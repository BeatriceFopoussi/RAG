{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création d’un Agent Chatbot Documentaire avec LangChain\n",
    "Durant cette partie, on va  construire un chatbot capable de répondre aux questions des utilisateurs en exploitant des documents PDF. En utilisant la bibliothèque LangChain, on va  développer un agent conversationnel qui peut extraire des informations à partir de fichiers PDF via un index vectoriel et interagir de manière fluide avec l’utilisateur.\n",
    "\n",
    "Ce TP mettra en avant l’implémentation d’un Retrieval-Augmented Generation (RAG), la gestion de la mémoire conversationnelle et l’intégration de plusieurs composants pour enrichir l’expérience utilisateur.\n",
    "\n",
    "Objectifs\n",
    "Comprendre comment un agent conversationnel peut exploiter des tools pour interroger une base documentaire (ex. : recherche dans des PDFs indexés).\n",
    "Expérimenter la notion de prompting pour guider un modèle de langage dans la reformulation et la synthèse des réponses.\n",
    "Intégrer des composants tels qu’un index vectoriel (FAISS), une base de données documentaire (SQLite) et un mécanisme de mémoire conversationnelle afin d’obtenir un chatbot capable de maintenir le contexte sur plusieurs échanges.\n",
    "* Base de code fournie\n",
    "\n",
    "\n",
    "Dans ce TP, vous disposerez d’une base de code qui comprend déjà :\n",
    "\n",
    "\n",
    "✅ Un pipeline d’extraction et de découpage du texte depuis des fichiers PDF.\n",
    "✅ Un moteur de recherche basé sur un index vectoriel (FAISS) pour retrouver rapidement les passages pertinents.\n",
    "✅ Un agent LangChain capable de traiter les requêtes des utilisateurs en interrogeant les documents PDF indexés.\n",
    "\n",
    "Plan du TP\n",
    "1️⃣ Extraction et prétraitement des données à partir des documents PDF.\n",
    "2️⃣ Indexation vectorielle du texte extrait avec FAISS.\n",
    "3️⃣ Construction des tools pour permettre à l’agent d’interroger les documents efficacement.\n",
    "4️⃣ Implémentation de l’agent conversationnel, intégration de la mémoire et ajustement du prompting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def extract_text_and_tables(\n",
    "    directory_path: str,\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Parcourt un répertoire et renvoie une seule liste de chaînes de caractères.\n",
    "    Cette liste contient, pêle-mêle :\n",
    "      - Les chunks de texte issus de chaque page PDF,\n",
    "      - Les chunks de texte issus de chaque table.\n",
    "\n",
    "    Pour les tables, on les transforme en texte en\n",
    "    séparant les cellules d'une ligne par \"|\" et\n",
    "    les lignes entre elles par des sauts de ligne.\n",
    "    \"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    results = []  # Une seule liste de strings\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    # --- 1) Texte normal ---\n",
    "                    raw_text = page.extract_text() or \"\"\n",
    "                    raw_text = raw_text.strip()\n",
    "\n",
    "                    if raw_text:\n",
    "                        chunks = text_splitter.split_text(raw_text)\n",
    "                        results.extend(chunks)\n",
    "\n",
    "                    # --- 2) Tables converties en texte ---\n",
    "                    page_tables = page.extract_tables() or []\n",
    "                    for table in page_tables:\n",
    "                        if not table:\n",
    "                            continue\n",
    "\n",
    "                        # Construit une représentation texte de la table\n",
    "                        # exemple : on sépare les cellules par \" | \"\n",
    "                        #          et on sépare les lignes par \"\\n\"\n",
    "                        lines = []\n",
    "                        for row in table:\n",
    "                            # row est une liste de cellules\n",
    "                            # on ignore le cas None pour éviter les erreurs de jointure\n",
    "                            cleaned_row = [cell if cell else \"\" for cell in row]\n",
    "                            line = \" | \".join(cleaned_row)\n",
    "                            lines.append(line)\n",
    "\n",
    "                        table_text = \"\\n\".join(lines).strip()\n",
    "\n",
    "                        # Puis, on chunk ce texte comme n'importe quel texte\n",
    "                        if table_text:\n",
    "                            table_chunks = text_splitter.split_text(table_text)\n",
    "                            results.extend(table_chunks)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\uf0d8 Moyen Pays : arrière-pays, composé de plaines et vallées\\n\\uf0d8 Haut Pays : territoire de montagne, 70 % de la superficie\\ndu département\\n• Trois quarts du territoire à plus de 700 mètres d’altitude\\nLe département des Alpes-Maritimes (Source : Larousse)\\n4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = extract_text_and_tables(\n",
    "    directory_path=\"documents\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "doc_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document as LangchainDocument  # Vérifiez si c'est le bon chemin\n",
    "\n",
    "def read_pdf_from_directory(directory_path: str) -> List[LangchainDocument]:\n",
    "    \"\"\"Read all pdf files in the specified directory and return a list of LangchainDocument objects.\n",
    "    \n",
    "    directory_path: Path to the directory containing PDF files.\n",
    "    \"\"\"\n",
    "    raw_documents = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.pdf'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            doc = PyPDFLoader(file_path).load()\n",
    "            raw_documents.extend(doc)\n",
    "    return raw_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Utilisation\n",
    "documents = read_pdf_from_directory('documents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_chunking(documents: List[LangchainDocument], chunk_size: int, chunk_overlap: int) -> List[str]:\n",
    "    \"\"\"Chunking the documents into smaller pieces wrt model max-length.\n",
    "    documents: List of LangchainDocument object.\n",
    "    max_length: Maximum length of the model.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                        chunk_size=chunk_size,\n",
    "                        chunk_overlap=chunk_overlap,\n",
    "                        add_start_index=True,\n",
    "                        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "                    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_embeddings_model(model_name: str = \"sentence-transformers/all-mpnet-base-v2\"):\n",
    "    embeddings_model = HuggingFaceEmbeddings(model_name = model_name, encode_kwargs={\n",
    "            \"normalize_embeddings\": True\n",
    "        })\n",
    "    return embeddings_model\n",
    "\n",
    "def create_vectorial_db(\n",
    "        chunks: List[LangchainDocument], \n",
    "        embeddings_model: HuggingFaceEmbeddings,\n",
    "        save_local_path: str = \"data/indexes/\"\n",
    "        ):\n",
    "    db = FAISS.from_documents(chunks, embeddings_model, distance_strategy=DistanceStrategy.COSINE,)\n",
    "    db.save_local(save_local_path)\n",
    "    return db\n",
    "\n",
    "def prepare_rag_data(\n",
    "        list_file_path: List[str], \n",
    "        chunk_size: int, \n",
    "        chunk_overlap: int, \n",
    "        embedding_model,\n",
    "        model_name: str = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        ):\n",
    "    \"\"\"Prepare RAG data by chunking them into smaller pieces wrt model max-length.\n",
    "    list_file_path: List of file path.\n",
    "    chunk_size: Chunk size.\n",
    "    chunk_overlap: Chunk overlap.\n",
    "    model_name: Model name.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reading pdf files...\")\n",
    "    documents = read_pdf(list_file_path)\n",
    "    print(\"Chunking the documents...\")\n",
    "    chunks = text_chunking(documents, chunk_size, chunk_overlap)\n",
    "    print(\"Initializing embeddings model...\")\n",
    "    print(\"Creating vectorial db...\")\n",
    "    index_name = (\n",
    "        f\"index_chunk-{chunk_size}_embeddings-{model_name.replace('/', '~')}\"\n",
    "    )\n",
    "    index_folder_path = f\"data/indexes/{index_name}//\"\n",
    "\n",
    "    if os.path.exists(index_folder_path):\n",
    "        db = FAISS.load_local(index_folder_path, \n",
    "                              embedding_model,\n",
    "                                distance_strategy=DistanceStrategy.COSINE,\n",
    "                                allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        print(\"Index not found, generating it...\")\n",
    "        db = create_vectorial_db(chunks, embedding_model, index_folder_path)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intégration des données dans une base SQLite\n",
    "\n",
    " Dans cette étape, nous allons commencer par attribuer un identifiant unique à chaque ligne de notre jeu de données dataset en créant une colonne id. Cet identifiant permettra de faire la correspondance entre l’index vectoriel et les données stockées dans la base. Ensuite, nous enregistrons ces informations dans une base SQLite (fichier products.db), de manière à disposer d’une table nommée products contenant toutes les colonnes initiales plus la colonne id. Pour vérifier que tout s’est bien déroulé, nous effectuons une requête de test (SELECT * FROM products LIMIT 5) et affichons les premières lignes. Après cette vérification, nous fermons la connexion à la base pour libérer les ressources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation des titre et indexation avec faiss\n",
    "Dans cette étape, nous allons vectoriser les titres de nos produits pour faciliter la recherche sémantique. D’abord, nous chargeons la colonne title de notre dataset et récupérons la liste d’IDs associée pour maintenir la correspondance avec la base de données. Ensuite, nous utilisons le modèle SentenceTransformerafin de convertir chaque titre en vecteur de dimensions réduites. Ces vecteurs sont ensuite indexés dans FAISS grâce à un IndexIDMap, qui associe chaque vecteur à l’ID unique correspondant. Enfin, l’index FAISS est sauvegardé dans un fichier (ici nommé vectors_with_ids.index), ce qui permettra de le recharger rapidement pour des recherches ultérieures sans avoir besoin de recalculer les embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:775: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `IndexToolConfig` to V2.\n",
      "  warn(\n",
      "/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import utils as u\n",
    "\n",
    "from utils import (\n",
    "    instanciate_llm_with_huggingface, \n",
    "    initialize_embeddings_model,\n",
    "    answer_with_rag,\n",
    "    run_rag_tests,\n",
    "    evaluate_answers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = extract_text_and_tables(\n",
    "    directory_path=\"documents\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "doc_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path=\"documents\",\n",
    "\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2' \n",
    "CHUNK_SIZE = 300\n",
    "CHUNK_OVERLAP = 50\n",
    "MAX_NEW_TOKENS = 500\n",
    "DO_SAMPLE = True\n",
    "TEMPERATURE = 0.8\n",
    "TOP_P = 0.9\n",
    "REPETITION_PENALTY = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "En utilisant les informations contenues dans le contexte,\n",
    "donnez une réponse complète à la question.\n",
    "Répondez uniquement à la question posée, la réponse doit être concise et pertinente par rapport à la question.\n",
    "Fournissez le numéro du document source lorsque cela est pertinent.\n",
    "Si la réponse ne peut pas être déduite du contexte, ne donnez pas de réponse.\n",
    "<|user|>\n",
    "Context:\n",
    "{context}\n",
    "---\n",
    "Voici maintenant la question à laquelle vous devez répondre.\n",
    "Question: {question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_PROMPT = \"\"\"###Task Description:\n",
    "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
    "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
    "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
    "3. The output format should look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n",
    "4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output.\n",
    "\n",
    "###The instruction to evaluate:\n",
    "{instruction}\n",
    "\n",
    "###Response to evaluate:\n",
    "{response}\n",
    "\n",
    "###Reference Answer (Score 5):\n",
    "{reference_answer}\n",
    "\n",
    "###Score Rubrics:\n",
    "[Is the response correct, accurate, and factual based on the reference answer?]\n",
    "Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
    "Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
    "Score 3: The response is somewhat correct, accurate, and/or factual.\n",
    "Score 4: The response is mostly correct, accurate, and factual.\n",
    "Score 5: The response is completely correct, accurate, and factual.\n",
    "\n",
    "###Feedback:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_PROMPT = \"\"\"### Description de la tâche : Une instruction (qui peut inclure une entrée à l'intérieur), une réponse à évaluer, une réponse de référence qui obtient un score de 5, et une grille de notation représentant des critères d'évaluation sont fournis.\n",
    "\n",
    "Rédigez un retour détaillé qui évalue la qualité de la réponse strictement en fonction de la grille de notation donnée, sans évaluer de manière générale.\n",
    "Après avoir écrit un retour, indiquez un score qui est un entier entre 1 et 5. Vous devez vous référer à la grille de notation.\n",
    "Le format de sortie doit ressembler à ceci : \"Feedback : {{rédigez un retour pour les critères}} [RESULT] {{un nombre entier entre 1 et 5}}\"\n",
    "Veuillez ne pas générer d'autres ouvertures, fermetures ou explications. Assurez-vous d'inclure [RESULT] dans votre sortie.\n",
    "## L'instruction à évaluer :\n",
    "{instruction}\n",
    "\n",
    "Réponse à évaluer :\n",
    "{response}\n",
    "\n",
    "## Réponse de référence (Score 5) :\n",
    "{reference_answer}\n",
    "\n",
    "## Grille de notation :\n",
    "\n",
    "[La réponse est-elle correcte, précise et factuelle par rapport à la réponse de référence ?]\n",
    " Score 1 : La réponse est complètement incorrecte, inexacte et/ou non factuelle. \n",
    " Score 2 : La réponse est principalement incorrecte, inexacte et/ou non factuelle. \n",
    " Score 3 : La réponse est quelque peu correcte, précise et/ou factuelle. \n",
    " Score 4 : La réponse est principalement correcte, précise et factuelle. \n",
    " Score 5 : La réponse est complètement correcte, précise et factuelle.\n",
    "\n",
    "Retour :\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Questions sur les Alpes-Maritimes\n",
    "questions = [\n",
    "    \"Quels sont les plats traditionnels des Alpes-Maritimes ?\",\n",
    "    \"Combien de musées y a-t-il dans les Alpes-Maritimes ?\",\n",
    "    \"Quelles sont les principales cascades des Alpes-Maritimes ?\",\n",
    "    \"Les Alpes-Maritimes ont-elles des falaises ?\",\n",
    "    \"Pouvez-vous me donner quelques sites d'écotourisme dans les Alpes-Maritimes ?\",\n",
    "    \"Où se trouve le Musée Marc Chagall ?\",\n",
    "    \n",
    "    \"Quelle est la population des Alpes-Maritimes ?\",\n",
    "    \"Quelle est la superficie des Alpes-Maritimes ?\",\n",
    "    \"Quand a lieu la célébration nationale en France ?\"\n",
    "]\n",
    "\n",
    "# Réponses correspondantes\n",
    "answers = [\n",
    "    \"Les plats traditionnels des Alpes-Maritimes incluent la Socca, le Pan Bagnat et la Ratatouille.\",\n",
    "    \"Il y a environ 30 musées dans les Alpes-Maritimes.\",\n",
    "    \"Les principales cascades incluent la Cascade de Gairaut et la Cascade de la Madone.\",\n",
    "    \"Oui, les Alpes-Maritimes ont des falaises, notamment le long de la côte.\",\n",
    "    \"Quelques sites d'écotourisme incluent le Parc National du Mercantour et la Vallée de l'Estéron.\",\n",
    "    \"Le Musée Marc Chagall est situé à Nice.\",\n",
    "    \"La population des Alpes-Maritimes est d'environ 1,1 million.\",\n",
    "    \"La superficie des Alpes-Maritimes est d'environ 4 300 kilomètres carrés.\",\n",
    "    \"La célébration nationale en France a lieu le 14 juillet.\"\n",
    "]\n",
    "\n",
    "# Création du DataFrame\n",
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers\n",
    "    }\n",
    ")\n",
    "\n",
    "# Affichage du DataFrame\n",
    "#print(eval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = initialize_embeddings_model(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-q24aiX6efr5M2SC5ySeVT3BlbkFJdlSFxh4bMKc6G2lL36t4'\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = instanciate_llm_with_huggingface(\n",
    "        model_name = \"mistralai/Mistral-7B-Instruct-v0.3\",  \n",
    "        max_new_tokens = MAX_NEW_TOKENS,\n",
    "        do_sample = DO_SAMPLE,\n",
    "        temperature  = TEMPERATURE,\n",
    "        top_p = TOP_P,\n",
    "        repetition_penalty = REPETITION_PENALTY\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
    "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_name = \"databricks/dolly-v2-12b\" #\"meta-llama/Llama-2-7b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "eval_chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "evaluator_name = \"GPT4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path=\"documents\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token key\n",
    "\n",
    "\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Remplacez 'your_token_here' par votre token d'accès\n",
    "login(token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-100_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:02,  1.11s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:03,  1.20s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:05,  1.43s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:06,  1.42s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:07,  1.17s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:08,  1.09s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:09,  1.01s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:09,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-100_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  5.23it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.69it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  5.77it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  5.65it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:00,  5.73it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  5.19it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.40it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.59it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-100_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:03,  3.32s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:04,  2.15s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:05,  1.40s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:06,  1.26s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:08,  1.51s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:08,  1.17s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:19,  4.37s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:21,  3.44s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:22,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:23<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-100_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  4.43it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.07it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  5.38it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  5.59it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:00,  5.65it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  5.87it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.37it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.27it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:19<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-100_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:02,  2.24s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:04,  2.04s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:04,  1.27s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:05,  1.14s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:07,  1.46s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:09,  1.62s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:09,  1.28s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:11,  1.22s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:12,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-100_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  5.80it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.61it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  5.54it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  5.41it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:00,  5.24it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  5.01it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.01it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.33it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-200_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Index not found, generating it...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:02,  2.31s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:04,  2.21s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:05,  1.58s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:07,  1.81s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:11,  2.52s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:12,  2.04s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:13,  1.75s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:15,  1.88s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:16,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:17<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-200_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  4.75it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.20it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  5.21it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  5.44it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:00,  5.23it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  5.41it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.37it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.17it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-200_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:01,  1.87s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:03,  1.95s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:04,  1.31s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:05,  1.24s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:07,  1.46s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:10,  1.86s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:11,  1.62s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:12,  1.37s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:12,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-200_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  6.05it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  2.61it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  3.53it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:01,  4.22it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:01,  4.39it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  4.52it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  4.72it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  4.76it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:02,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-200_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:03,  3.54s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:05,  2.39s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:06,  1.95s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:08,  2.04s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:14,  3.52s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:15,  2.60s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:17,  2.19s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:18,  1.90s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:18,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-200_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  4.56it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.18it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  5.20it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  5.12it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:00,  5.40it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  5.60it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.61it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.21it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-300_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Index not found, generating it...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:02,  2.52s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:04,  2.24s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:07,  2.49s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:09,  2.37s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:15,  3.64s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:16,  2.89s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:18,  2.43s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:19,  2.01s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:20,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-300_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  3.21it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  4.01it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  4.15it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  4.41it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:01,  4.84it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  4.80it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.20it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.27it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-300_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:01,  1.82s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:15,  8.85s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:17,  5.50s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:17,  3.65s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:22,  3.96s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:23,  2.84s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:24,  2.51s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:26,  2.17s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:39,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:15<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-300_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  6.10it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.57it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  4.69it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  4.78it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:01,  4.70it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  4.97it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.09it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.22it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:15<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-300_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:01,  1.88s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:05,  2.66s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:09,  3.30s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:11,  2.74s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:14,  3.00s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:15,  2.29s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:16,  1.78s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:18,  1.83s/it]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:18,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:17<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-300_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2:\n",
      "Loading knowledge base embeddings...\n",
      "Reading pdf files...\n",
      "Chunking the documents...\n",
      "Initializing embeddings model...\n",
      "Creating vectorial db...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "1it [00:00,  6.07it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "2it [00:00,  5.98it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "3it [00:00,  5.37it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "4it [00:00,  4.81it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "5it [00:00,  5.01it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "6it [00:01,  5.25it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "7it [00:01,  5.58it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "8it [00:01,  5.30it/s]/home/beatrice/.cache/pypoetry/virtualenvs/llms-IHN9N-5k-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "9it [00:01,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import time\n",
    "from langchain.schema import Document  # Assurez-vous d'importer le bon module\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def create_documents_from_text(text):\n",
    "    return [Document(page_content=text, metadata={})]  # Créez un document avec le texte et des métadonnées vides\n",
    "\n",
    "def prepare_rag_data(\n",
    "        list_file_path: List[str], \n",
    "        chunk_size: int, \n",
    "        chunk_overlap: int, \n",
    "        embedding_model,\n",
    "        model_name: str = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        ):\n",
    "    print(\"Reading pdf files...\")\n",
    "    documents = []\n",
    "    for file_path in list_file_path:\n",
    "        pdf_content = read_pdf(file_path)\n",
    "        documents.extend(create_documents_from_text(pdf_content))  # Créez des documents à partir du texte\n",
    "\n",
    "    print(\"Chunking the documents...\")\n",
    "    chunks = text_chunking(documents, chunk_size, chunk_overlap)\n",
    "    print(\"Initializing embeddings model...\")\n",
    "    print(\"Creating vectorial db...\")\n",
    "    index_name = (\n",
    "        f\"index_chunk-{chunk_size}_embeddings-{model_name.replace('/', '~')}\"\n",
    "    )\n",
    "    index_folder_path = f\"data/indexes/{index_name}//\"\n",
    "\n",
    "    if os.path.exists(index_folder_path):\n",
    "        db = FAISS.load_local(index_folder_path, \n",
    "                              embedding_model,\n",
    "                                distance_strategy=DistanceStrategy.COSINE,\n",
    "                                allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        print(\"Index not found, generating it...\")\n",
    "        db = create_vectorial_db(chunks, embedding_model, index_folder_path)\n",
    "    return db\n",
    "\n",
    "# Exemple de lecture de fichiers PDF dans un répertoire\n",
    "FILES = [os.path.join(\"documents\", f) for f in os.listdir(\"documents\") if f.endswith('.pdf')]\n",
    "\n",
    "# Créer le répertoire de sortie s'il n'existe pas\n",
    "if not os.path.exists(\"./output\"):\n",
    "    os.mkdir(\"./output\")\n",
    "\n",
    "for chunk_size in [100, 200, 300]:  # Ajouter d'autres tailles de morceaux (en tokens) si nécessaire\n",
    "    for temperature in [0.4, 0.8, 1.0]:\n",
    "        for embeddings in [MODEL_NAME]:  # Ajouter d'autres embeddings si nécessaire\n",
    "            for rerank in [True, False]:\n",
    "                settings_name = f\"chunk-{chunk_size}_temperature-{temperature}_embeddings-{embeddings.replace('/', '~')}_rerank-{rerank}_reader-model-{MODEL_NAME}\"\n",
    "                output_file_name = f\"./output/rag_{settings_name}.json\"\n",
    "\n",
    "                print(f\"Running evaluation for {settings_name}:\")\n",
    "\n",
    "                print(\"Loading knowledge base embeddings...\")\n",
    "\n",
    "                knowledge_index = prepare_rag_data(\n",
    "                    list_file_path=FILES, \n",
    "                    chunk_size=chunk_size,\n",
    "                    chunk_overlap=CHUNK_OVERLAP,\n",
    "                    embedding_model=embedding_model,\n",
    "                    model_name=embeddings,\n",
    "                )\n",
    "\n",
    "                print(\"Running RAG...\")\n",
    "                model = instanciate_llm_with_huggingface(\n",
    "                    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\",  \n",
    "                    max_new_tokens=MAX_NEW_TOKENS,\n",
    "                    do_sample=DO_SAMPLE,\n",
    "                    temperature=temperature,\n",
    "                    top_p=TOP_P,\n",
    "                    repetition_penalty=REPETITION_PENALTY\n",
    "                )\n",
    "                \n",
    "                # Ajoutez un délai pour éviter de dépasser le quota\n",
    "                time.sleep(1)\n",
    "\n",
    "                run_rag_tests(\n",
    "                    eval_dataset=eval_df,\n",
    "                    llm=model,\n",
    "                    knowledge_index=knowledge_index,\n",
    "                    output_file=output_file_name,\n",
    "                    reranker=False,\n",
    "                    verbose=False,\n",
    "                    test_settings=settings_name,\n",
    "                    rag_prompt_template=RAG_PROMPT_TEMPLATE\n",
    "                )\n",
    "\n",
    "                print(\"Running evaluation...\")\n",
    "                evaluate_answers(\n",
    "                    output_file_name,\n",
    "                    eval_chat_model,\n",
    "                    evaluator_name,\n",
    "                    evaluation_prompt_template,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "esult[\"eval_score_GPT4\"] = result.get(\"eval_score_GPT4\", pd.Series([1] * len(result))).apply(\n",
    "    lambda x: int(x) if isinstance(x, str) else 1\n",
    ")\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "outputs = []\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    output = pd.DataFrame(json.load(open(file, \"r\")))\n",
    "    output[\"settings\"] = file\n",
    "    outputs.append(output)\n",
    "result = pd.concat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>true_answer</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>retrieved_docs</th>\n",
       "      <th>test_settings</th>\n",
       "      <th>eval_score_GPT4</th>\n",
       "      <th>eval_feedback_GPT4</th>\n",
       "      <th>settings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les plats traditionnels des Alpes-M...</td>\n",
       "      <td>Les plats traditionnels des Alpes-Maritimes in...</td>\n",
       "      <td>Je suis désolé, mais je n'ai pas trouvé d'info...</td>\n",
       "      <td>[Alpes Carros CT ho âu terr ae ut nte e- uL fe...</td>\n",
       "      <td>chunk-300_temperature-0.4_embeddings-all-MiniL...</td>\n",
       "      <td>1</td>\n",
       "      <td>Feedback : La réponse fournie ne répond pas à ...</td>\n",
       "      <td>./output/rag_chunk-300_temperature-0.4_embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combien de musées y a-t-il dans les Alpes-Mari...</td>\n",
       "      <td>Il y a environ 30 musées dans les Alpes-Mariti...</td>\n",
       "      <td>Leurs du 2022\\nen 2022\\nles lignes Paillon, de...</td>\n",
       "      <td>[Alpes-Maritimes.\\nAménagement\\n20\\nPar décret...</td>\n",
       "      <td>chunk-300_temperature-0.4_embeddings-all-MiniL...</td>\n",
       "      <td>1</td>\n",
       "      <td>Feedback : La réponse fournie ne répond pas à ...</td>\n",
       "      <td>./output/rag_chunk-300_temperature-0.4_embeddi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Quels sont les plats traditionnels des Alpes-M...   \n",
       "1  Combien de musées y a-t-il dans les Alpes-Mari...   \n",
       "\n",
       "                                         true_answer  \\\n",
       "0  Les plats traditionnels des Alpes-Maritimes in...   \n",
       "1  Il y a environ 30 musées dans les Alpes-Mariti...   \n",
       "\n",
       "                                    generated_answer  \\\n",
       "0  Je suis désolé, mais je n'ai pas trouvé d'info...   \n",
       "1  Leurs du 2022\\nen 2022\\nles lignes Paillon, de...   \n",
       "\n",
       "                                      retrieved_docs  \\\n",
       "0  [Alpes Carros CT ho âu terr ae ut nte e- uL fe...   \n",
       "1  [Alpes-Maritimes.\\nAménagement\\n20\\nPar décret...   \n",
       "\n",
       "                                       test_settings eval_score_GPT4  \\\n",
       "0  chunk-300_temperature-0.4_embeddings-all-MiniL...               1   \n",
       "1  chunk-300_temperature-0.4_embeddings-all-MiniL...               1   \n",
       "\n",
       "                                  eval_feedback_GPT4  \\\n",
       "0  Feedback : La réponse fournie ne répond pas à ...   \n",
       "1  Feedback : La réponse fournie ne répond pas à ...   \n",
       "\n",
       "                                            settings  \n",
       "0  ./output/rag_chunk-300_temperature-0.4_embeddi...  \n",
       "1  ./output/rag_chunk-300_temperature-0.4_embeddi...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result.shape)\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"eval_score_GPT4\"] = result[\"eval_score_GPT4\"].apply(\n",
    "    lambda x: int(x) if isinstance(x, str) else 1\n",
    ")\n",
    "result[\"eval_score_GPT4\"] = (result[\"eval_score_GPT4\"] - 1) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "settings\n",
       "./output/rag_chunk-100_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.027778\n",
       "./output/rag_chunk-100_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.055556\n",
       "./output/rag_chunk-100_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.194444\n",
       "./output/rag_chunk-100_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.194444\n",
       "./output/rag_chunk-300_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.222222\n",
       "./output/rag_chunk-300_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.250000\n",
       "./output/rag_chunk-300_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.305556\n",
       "./output/rag_chunk-300_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.333333\n",
       "./output/rag_chunk-100_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.416667\n",
       "./output/rag_chunk-100_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.416667\n",
       "./output/rag_chunk-200_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.472222\n",
       "./output/rag_chunk-200_temperature-0.8_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.500000\n",
       "./output/rag_chunk-200_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.500000\n",
       "./output/rag_chunk-300_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.500000\n",
       "./output/rag_chunk-200_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.500000\n",
       "./output/rag_chunk-300_temperature-1.0_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.500000\n",
       "./output/rag_chunk-200_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-True_reader-model-all-MiniLM-L6-v2.json     0.555556\n",
       "./output/rag_chunk-200_temperature-0.4_embeddings-all-MiniLM-L6-v2_rerank-False_reader-model-all-MiniLM-L6-v2.json    0.583333\n",
       "Name: eval_score_GPT4, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores = result.groupby(\"settings\")[\"eval_score_GPT4\"].mean()\n",
    "average_scores.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunk_size(text):\n",
    "    res = text.split(\"rag_chunk-\")[1].split(\"_\")[0]\n",
    "    return res\n",
    "\n",
    "def extract_temperature(text):\n",
    "    res = text.split('temperature-')[1].split(\"_\")[0]\n",
    "    return res\n",
    "\n",
    "def extract_rerank(text):\n",
    "    res = text.split(\"rerank-\")[1].split(\"_\")[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>settings</th>\n",
       "      <th>eval_score_GPT4</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./output/rag_chunk-100_temperature-0.4_embeddi...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./output/rag_chunk-100_temperature-0.4_embeddi...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./output/rag_chunk-100_temperature-0.8_embeddi...</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./output/rag_chunk-100_temperature-0.8_embeddi...</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./output/rag_chunk-100_temperature-1.0_embeddi...</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            settings  eval_score_GPT4  \\\n",
       "0  ./output/rag_chunk-100_temperature-0.4_embeddi...         0.416667   \n",
       "1  ./output/rag_chunk-100_temperature-0.4_embeddi...         0.416667   \n",
       "2  ./output/rag_chunk-100_temperature-0.8_embeddi...         0.194444   \n",
       "3  ./output/rag_chunk-100_temperature-0.8_embeddi...         0.194444   \n",
       "4  ./output/rag_chunk-100_temperature-1.0_embeddi...         0.027778   \n",
       "\n",
       "  chunk_size temperature rerank  \n",
       "0        100         0.4  False  \n",
       "1        100         0.4   True  \n",
       "2        100         0.8  False  \n",
       "3        100         0.8   True  \n",
       "4        100         1.0  False  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_results = pd.DataFrame(average_scores).reset_index()\n",
    "formated_results['chunk_size'] = formated_results['settings'].apply(extract_chunk_size)\n",
    "formated_results['temperature'] = formated_results['settings'].apply(extract_temperature)\n",
    "formated_results['rerank'] = formated_results['settings'].apply(extract_rerank)\n",
    "formated_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_results[['temperature', 'chunk_size']] = formated_results[['temperature', 'chunk_size']].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>settings</th>\n",
       "      <th>eval_score_GPT4</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./output/rag_chunk-100_temperature-0.4_embeddi...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./output/rag_chunk-100_temperature-0.8_embeddi...</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./output/rag_chunk-100_temperature-1.0_embeddi...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./output/rag_chunk-200_temperature-0.4_embeddi...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./output/rag_chunk-200_temperature-0.8_embeddi...</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            settings  eval_score_GPT4  \\\n",
       "1  ./output/rag_chunk-100_temperature-0.4_embeddi...         0.416667   \n",
       "3  ./output/rag_chunk-100_temperature-0.8_embeddi...         0.194444   \n",
       "5  ./output/rag_chunk-100_temperature-1.0_embeddi...         0.055556   \n",
       "7  ./output/rag_chunk-200_temperature-0.4_embeddi...         0.555556   \n",
       "9  ./output/rag_chunk-200_temperature-0.8_embeddi...         0.472222   \n",
       "\n",
       "   chunk_size  temperature rerank  \n",
       "1       100.0          0.4   True  \n",
       "3       100.0          0.8   True  \n",
       "5       100.0          1.0   True  \n",
       "7       200.0          0.4   True  \n",
       "9       200.0          0.8   True  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_results = formated_results[formated_results[\"rerank\"]==\"True\"]\n",
    "formated_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIpCAYAAACotAmxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgOZJREFUeJzs3Xd8FHX+x/H3bHoPLQktEEApIr1IUUECURQBRRA8gajYEAunAhZQLHiiiKcI6omI5cACNhALCopwclIEQVF6TegJpGf3+/uDX/ZYU8gkmwJ5PR+PfTzIzPc789mZYbPvzMx3LGOMEQAAAACg2BwVXQAAAAAAnG0IUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFJABWjYsKEsyzrja86cORVS386dO2VZlho2bFgh6weA8jJy5MgK/bwtrmXLlsmyLPXo0aOiS5F09mw3oCz5VnQBQFXWrVs3NWnSpND5Rc0DvGnkyJF666239Oabb2rkyJEVXU6VYlmWJMkYU8GVAADsIEgBFeiWW27hSysA4KwzZcoUjR8/XrVr167oUoAKQ5ACAACALbVr1yZEocrjHingLPD777/LsixVq1ZNmZmZhbbr0KGDLMvSJ5984p62efNmTZo0Sd26dVPdunXl7++vGjVqKD4+Xu+//75X6zxw4IDuuecenX/++QoMDFRwcLDq16+vXr166bnnniuwz759+/TAAw/owgsvVFhYmEJCQnT++edr5MiRWrlyZb72e/fu1ZgxY3TeeecpMDBQERER6tatm1599VU5nc587efMmSPLsjRy5EgdPXpU9957rxo3bqyAgIB89xosXbpU11xzjWrXri1/f39FRUVp4MCBWrVqle1tkXcf3M6dO7Vw4UJ1795d4eHhCgsLU48ePbR48eIC++3atUv/+Mc/dNlllyk2NlYBAQGKjIxU9+7d9eqrr8rlcuXrc/o9bU6nU9OmTVPbtm0VGhrqvmysMHl933rrLUlSYmKix316jz32mEf7jIwMPf/887rooosUGRmpwMBANW3aVA8++KCOHDmSb/mnb/+UlBSNHTtWDRs2VGBgoM477zz94x//cL+nffv26bbbblP9+vUVEBCgpk2b6qWXXiqw7h49esiyLC1btkzLly9Xnz59VL16dQUHB6tTp056++23i3zfdvd13vaQpDfffFNdunRRRESEex9L9vfdY4895rF//nqPZN5y89r9dV/kKezemdOnp6ena+LEiWrevLmCg4Pz3f+4Zs0a3XDDDe66q1evroSEhEKP04I4nU7Vq1dPlmXpP//5T6Ht7r//flmWpfvuu889LSsrS1OnTlX79u0VFhYmf39/xcTEqGPHjnrwwQd19OjRYtchSbm5uZo9e7bi4+NVs2ZNBQQEqF69eoqPjy/0mJKkHTt26MYbb1RMTIwCAgLUuHFjPfLII8rKysrX9kz3CJ1+7Bc2PS0tTRMmTFCTJk0UEBCgmJgYjRgxQvv27bP1fg8dOqSuXbvKsiwNGTKkwHqL44MPPlB8fLxq1KghPz8/1ahRQy1atNCoUaO0YcMGj7YFvf+8Y+5Mr2XLluVb94cffqjLL79ctWrVkr+/v+rWrau//e1v2rx5c4neC1AuDIBy16BBAyPJvPnmm8Xu06VLFyPJ/Pvf/y5w/oYNG4wkEx0dbXJyctzTb775ZiPJNGvWzCQkJJghQ4aYLl26GIfDYSSZ++67L9+yduzYYSSZBg0aFLu+AwcOmDp16hhJJjY21vTv398MGTLEXHzxxaZ69eomIiIiX59vvvnGREZGGkkmKirK9O/f31x33XWmY8eOxs/Pz4wYMcKj/erVq0316tXd6xgyZIi5/PLLTWBgoJFkEhISTFZWlkefN99800gyV155pYmLizPVqlUzV199tbnuuuvMDTfc4G7397//3UgyDofDdOrUyVx33XWmc+fOxrIs4+PjY2bPnl3sbWHM//bxfffdZySZDh06mKFDh5pOnToZSUaS+ec//5mv3xNPPGEkmbi4ONOrVy9z/fXXm0svvdT4+/sbSeaaa64xLpfLo0/e/oqNjTVXX3218ff3N7169TJDhw41rVq1KrLOQ4cOmREjRpjGjRsbSaZbt25mxIgR7tfChQvdbfft22cuvPBCI8lUr17dxMfHm4EDB7rfa8OGDc3OnTsL3P79+/c3zZs3N1FRUebaa681ffr0MUFBQUaSueuuu8zWrVtNTEyMqV+/vhk8eLDp2bOn8fHxMZLMM888k6/uSy+91Egyd999t3E4HKZFixbm+uuvN5dccon72B47dmyB77kk+zpvn911113G4XCY7t27m6FDh5rOnTu737Pdfbdw4UIzYsQI97JP3+4jRowwhw4dMsYYM2nSJCPJTJo0qcD389133xlJ5tJLLy1weufOnU3Hjh1NSEiIueKKK8yQIUNMfHy8u9306dPd26xNmzZm0KBBpnv37u66H3/88QLXW5AJEyYYSea2224rcH5OTo6Jjo42ksyGDRuMMcY4nU7Tq1cvI8mEh4ebK664wgwdOtTEx8e7j61169YVu4bjx4+b7t27G0nGz8/PXHrppWbo0KGmZ8+eplatWuavX33y9sE999xjwsPDTYMGDczgwYNNfHy8+xgdMGBAvvXk9Svsczzv2P/r51je9AEDBphWrVqZyMhI069fP9O/f38TFRXl/uw9fvy4R7/C9vOWLVvc/38ffPDBfJ8PxfX4448bScbX19dccsklZujQoaZv376mZcuWxrIs88ILL5zx/f/222/5juO814ABA9zH+vfff+/uk5OTYwYPHmwkmYCAANO1a1dz3XXXmdatWxtJJigoyHzxxRclek9AWSNIARWgJEHq9ddfd4eFguR9Yf/73//uMX3ZsmVm27Zt+dr//vvvpl69ekaS+emnnzzmlSRI5f0SvvXWW/P9Is/OzjbffPONx7Tdu3ebiIgII8mMHz8+XwBKTk42P/zwg/vnzMxM93a7/fbbTXZ2tnvetm3bTMOGDY0k89BDD3ksJ+9LiyTTq1cvk5KSkq/21157zUgyTZo0Mb/88ovHvOXLl5uwsDDj7+9v/vjjj2Jvj7xaLcsy77zzjse8efPmGcuyjK+vr9m4caPHvNWrV+ebZsypEJP3xeL999/3mJe3vySZevXqmS1bthS7zjxn+lLocrlMt27djCRz8803m9TUVPe8nJwcdzjp2bOnR7/Tt3+/fv1MWlqae96aNWuMr6+vOwjdfvvtHn8E+Pjjj91frk/vZ8z/gpQk8/TTT3vMW7ZsmfsL8JIlSzzmlXRf560rPDzcrFq1qsBtVJJ9d/qyC1PaICXJtGrVyhw4cCBf3yVLlhjLskzNmjXN8uXLPeZt2LDB/RmxbNmyQus73R9//GEkmcjISJORkZFv/ieffGIkmfbt27unLV++3Egybdu29Tiu8vz3v/81hw8fLtb6jTHmmmuucS9vx44dHvNycnLMxx9/7DHt9DD78MMPm9zcXPe8jRs3mpCQECPJrFy5ssB+JQ1SeZ/np38mHT161LRp06bA47qg/fz999+b6tWrGx8fHzNr1qwzbJnCZWZmmqCgIBMaGmp+//33fPN37txpfvvtN49pZ3r/p8vKyjI9e/Y0kszgwYM9fkc89NBD7sC/fft2j34ffPCB8fHxMdWqVTPHjh0r0XsDyhJBCqgAeV+yz/Q6/RdHamqqCQ4ONg6Hw+zdu9djednZ2e6/tP7666/FruPVV181kswDDzzgMb0kQerOO+80ksyCBQuK1f7ee+91f7kujrfffttIMnXq1DGZmZn55n/44YdGkgkLC/P4Apf3pcXPz6/AQOl0Ot1n0n7++ecC1/3ss88WGFKLkrePC/pLtjHGXHvttUaSGTVqVLGX+eWXXxpJ5rrrrvOYfnqQmjt3brGXd7ozfSn64osv3GcsTg87eZxOp2nZsqWR5BEm8rZ/aGioSU5Oztfv6quvdp9NK+iLd94ZsL9+yc8LUm3bti2w3rxg17t3b48aS7qv87bv5MmTC+x3JoXtu9OXXRhvBKnTzwCcrnPnzkaS+fDDDwuc//777xtJ5tprry20vr+6+OKLjSTz3nvv5ZuXd1bi5ZdfzreOu+++u9jrKMz69euNJBMYGJjvc7Iwecd++/btCzybc/vttxe470sbpEJCQsz+/fvz9Zs3b56RZC677DKP6X/dz++9954JCAgwoaGhZvHixcV6r4U5ePCgO3AXV3GDlMvlMsOGDTOSzMUXX+zx+X3kyBETFBRU5P7K+93y0ksvFbs2oLww2ARQgc40/Lm/v7/732FhYRo0aJDmzp2ruXPnasKECe55ixYt0qFDh9SpUyddcMEF+ZZz8uRJffHFF1q3bp0OHz6s7OxsSafuaZKkLVu2lPq9dOrUSa+88orGjx8vY4z69Omj0NDQQtsvWbJEknTrrbcWa/l519Rff/31CggIyDf/mmuuUbVq1XTs2DGtWbNG3bp185jftm1bNWrUKF+/devWaf/+/WrcuLHat29f4Lrz7j0p6J6tMxkxYkSh0z/66KMC7xXIysrSV199pf/+9786ePCgsrKyZIzRiRMnJBW9v6699lrbNRbHokWL3Mv39c3/q8PhcOiSSy7Rr7/+qpUrV6ply5Ye89u3b6+oqKh8/c477zxJUs+ePRUYGFjg/I0bN2r//v0F1jV8+PACp48YMULPP/+8VqxYIafTKR8fH6/s60GDBhU4PU9p9l1ZiYqK0sUXX5xv+uHDh7V69WoFBQWpX79+BfYtybGfmJioH374QXPmzNHQoUPd0w8dOqRFixYpICBAw4YNc09v166dfHx8NHv2bJ1//vnue9dKIu9z5corr1TdunVt9b3qqqsKvKewefPmkmT7vqUz6dChQ4Hvszjre/rpp/XII4+odu3aWrRokdq0aVOqWmrVqqWGDRtqw4YN+vvf/66bb75ZLVq0KNUy8zz00EN677331KxZM33yyScen9/fffedMjIy1KtXr0L3V48ePfTKK69o5cqVuuuuu7xSE+AtBCmgAtkd/vymm27S3LlzNWfOHI8g9eabb0o69QXmrz777DMlJiYWOBBAntTU1OIXXYgbb7xRX3/9td59911de+218vHxUYsWLdS9e3cNGjRIl112mUf7Xbt2SZKaNWtWrOXnfamIi4srcL5lWYqLi9OxY8cK/AJS2MOFt2/fLknatm3bGQdmOHToULFqPV1h9eZN37t3r8f0//znPxoyZIh2795d6DIL219RUVEKDg62XWNx5G2nRx99VI8++miRbQvaTrGxsQW2zQvbhc0PCwuTpEIHWTnT9s3IyNCRI0cUFRXllX1d1EOqS7PvylJhNe/YsUPGGGVkZBT4x4nT2Tn2Bw8erLvvvlvffPON9u7dq3r16kmS3nnnHeXk5GjIkCGqVq2au33jxo31wgsv6IEHHtBdd92lu+66Sw0aNFCXLl101VVX6brrrvP4o1JR7H6unK6wYzA8PFxS4cdgSZV0fT/++KOWL1+uwMBAff/992rcuLFX6pk7d64GDRqkadOmadq0aapevbo6d+6s3r1768Ybb1TNmjVtL3PWrFl65plnFBMToyVLlnjsd+l/nytLly4tk89foKwRpICzyCWXXKLGjRvrjz/+0MqVK9W1a1cdPHhQixcvVmBgoK6//nqP9vv27dOQIUOUkZGhBx98UDfccIMaNmyo0NBQORwOffXVV0pISPDKg0AdDofeeecdPfTQQ1q0aJF+/PFH/fjjj5o5c6Zmzpypfv36aeHChfLx8Sn1ukoiKCiowOl5I6nFxMQoISGhyGWU5IvEmZy+7dPT0zVgwAAlJycrMTFRd9xxh5o0aaLw8HD5+Pjojz/+UNOmTQvdX4W9R2/I207du3c/4xe3gs6KOhxFDxJ7pvmlkbe9vLGvC9vGpd13pVHQSI7FqTmvX2hoqFfPZIaEhGjw4MGaPXu25s6dq4ceekiS3KO7FfQHnzFjxmjw4MH69NNPtWLFCq1YsULz5s3TvHnzNGnSJP3www9lPtS2t4/BM+2Xkq7vggsukJ+fn37++WeNGTNGH330kVf+71988cXauXOnFi1apOXLl2vlypX68ssv9cUXX2jSpElauHChevXqVezlff7557rrrrsUGhqqRYsWqUGDBvna5G2jJk2a5LuK4K9KEo6BskaQAs4ieUPmPvroo3rzzTfVtWtXvfPOO8rNzdXgwYMVGRnp0f6zzz5TRkaGBg4cqH/84x/5lvfnn396vcYWLVqoRYsWeuCBB2SM0bfffqthw4bps88+09y5c91fomJjY7Vlyxb9/vvvRV7emCfvso+8v2AWZMeOHR5ti6N+/fqSpBo1ahQ6jHFp7NixQ61bt843PW9o67y/1kvS999/r+TkZLVr106zZ8/O16cs9ldx5W2n/v376/7776+wOv4qb5//Vd72DQwMVI0aNSSV7b4uy32XdzYm7/LAv8o7C2NX3vawLEuzZ8/2apBITEzU7NmzNWfOHD300ENau3atNmzYoHr16ql3794F9omOjtaoUaM0atQoSace+3DTTTdp1apVGj9+vHuI/qLkneX5/fffvfZeClNW++VMIiMj9emnn+qqq67SF198oSuuuEKff/55kZdSF1dQUJAGDRrkvoT10KFDeuSRR/Taa6/ppptuKvZ7+u9//6shQ4bIsix98MEHateuXYHt8o7Bpk2blsnnL1DWeI4UcJYZOXKkHA6H3n//faWnpxd5WV/es1cK+kugMUbvvfdemdZqWZZ69erlvh9i/fr17nmXX365JOn1118v1rLy7tWYP39+gZe8LFy4UMeOHVNYWFih978UpGPHjqpZs6Y2b96sTZs2FbtfcRX2PKO5c+dK+t/7kv63vwq75Oedd97xbnGnyftSmJubW+D8K664QtKp58yUxVmVkipsm+Rt3+7du7vv6SrLfV2afefn5yep8G2f94eB3377rcD5efev2VWnTh21atVKJ06ccN9b5C3du3fX+eefrz///FM//vij+3NqxIgRxQ5szZo107hx4yR5fnYUJe9zZfHixYXeV+ctRe0XY4y++OKLMlt3eHi4lixZoj59+mj58uWKj4/XsWPHvL6eWrVq6dlnn5Uk7d69u1jr2L59u6666iqlp6dr1qxZ7n1SkF69esnf31/Lli3TwYMHvVY3UF4IUsBZJu8vuqmpqXrooYf066+/KjY2Nt89SNL/blr+8MMP3QNLSKcenDlx4sQSDZ5QmLlz52rNmjX5pp84ccI9oMLpgW7s2LEKCwvTp59+qkceeUQ5OTke/Q4ePKgVK1a4f77uuusUGxur/fv3a+zYsR5fOnfs2KG///3vkk5dIlTQoAWF8fPz06RJk2SM0cCBAz3WmcfpdOrbb78t8iGjhVm4cKHmzZvnMe3DDz/URx99JF9fX40ZM8Y9PW9/LV26NN9DKF977TXNnz/f9vqLK+/MWGEBo3///urYsaNWr16txMTEAu9XOHbsmGbNmlVoICgLa9ascX/Ry7NixQrNmDFDkjwe+lqW+7o0++5M2/6yyy6Tw+HQl19+qeXLl7unG2P0z3/+Ux999JGtWk/35JNPSjr1h5jPPvss33xjjH766Sd99dVXtped98edWbNmuf9oU9A9od9++60WL16c7zPAGKPPP/9cUsF/DCpImzZt1L9/f2VkZKh///757lfLzc3Vp59+avetFCg+Pl7SqT+WnL7Pc3JyNG7cOP33v//1ynoKExwcrM8++0zXXHONfvrpJ/Xo0UPJycklWtauXbv0r3/9q8B7+PKOi2rVqrnv3yrMkSNHdMUVV+jgwYOaOHGibr755iLbR0dHa8yYMUpLS1O/fv20cePGfG2ysrL06aeflstZRsC28h4mEMD/hsb+68NP//p69913C+yfNzxu3mvixIkFtsvJyTHt27d3Dz995ZVXmsGDB5sGDRoYPz8/M27cuAKHTS7J8Of9+/d3D0/et29fc8MNN5i+ffu6nxXVsmXLfM+I+fLLL01YWJiRTj1IeMCAAea6664znTp1OuMDeRs0aGCGDBli+vbtW6wH8v51WX/1wAMPuLfnBRdcYPr372+uv/5606NHD/dDg2fOnFns7ZG3j/OGee/YsaMZNmyYe7hpSWbatGmFbkd/f3/Tp08fc/3115tmzZoZy7LMww8/XOB+Kcn++qtffvnFOBwO43A4THx8vElMTDQ333yz+eSTT9xt9u3b537GTUhIiOnatau5/vrrzTXXXGPatGnjfoBuQcPPF7b9zzS0d2FDLP/1gbwXXHCBGTp0qLn00kvdD5e95557ClxmSfZ1XvuilGTfGWPM/fffbySZmjVrmsGDB5ubb77Z3HzzzR7PTrrnnnuMJOPj42N69OhhrrnmGtO4cWPj5+dnxo8fX+Tw53+d/lcvvvii8fX1NdKp52tdeeWVZtiwYaZ3797uB8SOGzeuyGUUZN++fe5jQpK55JJLCmz3wgsvGOnUM7p69Ohhhg0b5vGg54iICFsP5D169Ki56KKL3Psib5mXXXZZkQ/ktTuMuTH/2+dBQUGmd+/e5uqrrzb16tUz4eHh7n1W2PDnhf2fKOz/c2H7Mzc319x4441Gkjn//PPN7t27i9g6BVu3bp37MREdO3Y0gwcPNoMHDzZt27Y10qnn4f3rX//y6FPQdps8ebKRZIKDg4v83Xb6M6lycnLcw6M7HA7Ttm1bc+2115ohQ4aYbt26uZ/jxUN5URkRpIAKUNznSBX2RTAzM9MdKCzLyvcQw9OdOHHCPPTQQ6Zp06YmMDDQREVFmQEDBpiff/650F/MJfli/v3335t7773XdOrUycTExBh/f38TExNjunTpYl566SVz8uTJAvvt2rXL3HPPPe76QkNDzfnnn29uuummAh98unv3bjN69GjTqFEj4+/vb8LCwkyXLl3MzJkzC3y+UXGDlDHG/Pjjj+aGG24wDRo0MAEBASYsLMycf/75ZsCAAeZf//qXOXr0aLG3R94+3rFjh3n//fdNly5dTGhoqAkJCTEXX3yx+eyzzwrsl52dbaZOnWouvPBCExwcbKpXr2769Oljvvrqq0L3izeClDHGLFy40HTr1s2EhYUZy7IKDDiZmZlm1qxZpmfPnqZGjRrG19fXREVFmTZt2pjRo0ebL7/80qN9WQep7777zixdutT06tXLREREmKCgINOhQwczZ86cIt+r3X1dnCBVkn1njDEZGRnmwQcfNE2aNDH+/v7udZ3+MFmXy2Wef/5507x5c+Pv72+qV69u+vXrZ9asWXPG50idKUgZc+rBs7feeqs577zzTGBgoAkODjaNGjUyCQkJ5p///KfZt2/fGZdRkL59+7rfT2FBZevWreaxxx4zvXr1MrGxsSYwMNBUq1bNtGrVyowfP97s2bPH9nqzsrLMzJkzzcUXX2wiIyONv7+/qVevnundu7eZMWOGR9vSBKnMzEzzyCOPmEaNGhk/Pz8TFRVlhg4darZu3XrG50h5K0gZc+r4uOOOO9z9/vzzz0K2TMFSU1PN9OnTzcCBA815553n/qw6//zzzfDhwwt87lpB2y3v//OZXt99912+5S1evNhcc801pm7dusbPz89ERkaa5s2bm+uvv9689957+R7KDVQGljGV6GJ3ADhHNGzYULt27dKOHTuKHDIbJdOjRw8tX75c3333ncd9ZgAAlBfukQIAAAAAmwhSAAAAAGATz5ECAAA4h/zrX/8qcFTKgtSsWVPPPfdcGVcEnJu4RwoAAOAcMnLkyGI9wFg6NbR83gOsAdhDkAIAAAAAm7hHCgAAAABsqvL3SLlcLu3fv19hYWGyLKuiywEAAABQQYwxOnHihOrUqSOHo+hzTlU+SO3fv1/169ev6DIAAAAAVBJ79uxRvXr1imxT5YNUWFiYpFMbKzw8vIKrAQAAAFBRUlNTVb9+fXdGKEqVD1J5l/OFh4cTpAAAAAAU65YfBpsAAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2FTlH8gLAKi6XCZXxuTKyKlcV7oclq98HaFymWz5OkIqujwAOGcZY+Q06bLkq1xzUjJGvo4QGRn5WIGyrMp/vocgBQCocnJd6bLk0L6Tn2tn6js6mbPVPc8hP8WE9FajiJsU4tdQluUnh+VTgdUCwLnDZbJlZHQsc522p8zW4YxVkox7frWAdmoUMVI1g7tJRvJxBFRcsWdgGWPMmZudu1JTUxUREaGUlBSFh4dXdDkAgDKW68rQvhMf6/djL8hp0otsG+7fXB2iZ8jfJ1IOy7+cKgSAc5PTlamTOdu09uB9ysjdX2Rbf58aal1riqoFtJWvI6icKrSXDSr/OTMAALzE6crQ1uOztOnoU2cMUZKUmv2bVuy7Vpm5yXK5csuhQgA4NzldmTqWtV6rDtx4xhAlSdnOI/pv0u1KTv9WTldGOVRoH0GqEsnKyFZaarqyMrIruhQAOOfkujK09+Rn2p7yhq1+2a5j+s+BRDlN5fxFDgBng4zcA1qTPEYuY+d7rksbDj2slOzf5DLOMqutpAhSlUBGWqYO7zuqtx9/X9NGzdLcx+br0N4jykjLrOjSAOCcYcmhLceml6hvpjNJ21PmyOnicxkA7Mp1pen3o8+V6A9SRrn67cg/ZGwFsPJRqYLU999/r379+qlOnTqyLEsff/zxGfssW7ZM7dq1U0BAgJo0aaI5c+aUeZ3elJmWqUWvfa1hsbdr/rOf6PsPVun9qZ/qhgZ36POZXymTMAUApeYyTiWlf6NcV2qJl7HnxIeSZXmxKgCoGpwmSwczfihx/5TsTcW6HLC8VaoglZaWptatW2vGjBnFar9jxw5deeWV6tmzp9avX697771Xt9xyi7788ssyrtR7dm7ao1f/Pld/HfPDGKPXHnxb2zfurqDKAODcYUy2dqS8VaplZLuO6FD6DzLG5aWqAODc53RlamfKO5JK99m5LeUN5brSvFOUl1Sq4c+vuOIKXXHFFcVuP2vWLMXFxen555+XJDVv3lwrVqzQCy+8oISEhLIq02vSU9M175mPi2wz75mFGj93jILDg8unKAA4B1mWr1KzN5d6OYczVqlmUDf5WuU3ghQAnM1cytHRzJ9LvZxjmeskVa6rAirVGSm7Vq1apfj4eI9pCQkJWrVqVaF9srKylJqa6vGqKA4fh/5cu73INlvX7ZTDl+eXAEBpeOveplzXCUmV74ZnAKisLFn//9lZOjmuE3JYleoc0NkdpJKSkhQdHe0xLTo6WqmpqcrIKPhmtilTpigiIsL9ql+/fnmUWiCXyyisWmiRbUIjg2VcXEYCAKXhrV++DitAZ/mvTgAoV0Z5n52l42MFVLpLq6vcb4MJEyYoJSXF/dqzZ0+F1eLn76s+I3sU2abPyB7y9atc6RsAzjYOy1++jrBSLyfIt54clp8XKgKAqiPIt7YXllFHppJdEXBWB6mYmBglJyd7TEtOTlZ4eLiCggq+fj0gIEDh4eEer4riF+CnvqPi1aBFvQLnxzavp6tu7S2/AH5pA0BpOE2W6ob2L+VSHIoNH0SQAgAb/ByhahA+rNTLiQ0b7JUzW950VgepLl26aOnSpR7Tvv76a3Xp0qWCKrLPP9BP/1z5lPrd0UdBoYGSpKDQQPW7o4/+ueop+Qf5V3CFAHD283UEq1HEiFIto1ZQd/lYgV6qCACqjsjAVgryrVvi/r6OMMWE9Kl090hVqmpOnjyprVu3un/esWOH1q9fr+rVqys2NlYTJkzQvn37NHfuXEnS7bffrpdfflkPPvigbrrpJn377bd6//33tWjRoop6C7Y5HA4Fhwdr1D9u1B0vJCozLVOBIYHKzc51BysAQOn5OSJUM6irDmesLFH/xpGj5OsI8XJVAFAVWIoLH67NR6eUqHf90EEypRw+vSxUqjNSP//8s9q2bau2bdtKksaOHau2bdtq4sSJkqQDBw5o9+7/PVcpLi5OixYt0tdff63WrVvr+eef17/+9a+zYujzvwoKDZSfv6/CqoXKz9+XEAUAXubrCFbbWs8pyLfgy6mLcl7kaIX7NyuDqgDg3Odj+at+2LWKCY4/c+O/qB7YQedXGy1fR+V77IRl/vok2ComNTVVERERSklJqdD7pQAAZc9lnMpxpeinA4k6mbOtWH3OixyjRhEj5OPgD1wAUBpOV6Y2Hp6k/WnFu3qsZlBXtYt6sVxDlJ1sQJAiSAFAlWKMSy6TpT0nFmhn6rtKz92dr40lX0UH91CjyFsU6te4Uv4lFADORk5Xpo5krtb2lDd1NPO/BbaJ8G+puIiRig7uKR9H+Q4wQZCygSAFAFWTy+TIGJdSs3/TwfRlynGlymH5K8i3juqG9pfD8uWeKAAoA8a45DSZynGlaO+JT5TtPCLJyM8nUnVCrlSgb4wclr8clk+512YnG1SqwSYAACgvDstPsqRqgW0UEdBSLpMjSw45LD9ZVqW6hRgAzimW5ZCvFSxfR7CaRI6Sy+RI0v9//pZ/eCopghQAoMpzWL6VblhdAKgKLMtHPmdReDodf3IDAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMCmShekZsyYoYYNGyowMFCdO3fW6tWrC22bk5OjyZMnq3HjxgoMDFTr1q21ZMmScqwWAAAAQFVUqYLU/PnzNXbsWE2aNElr165V69atlZCQoIMHDxbY/pFHHtGrr76ql156SZs3b9btt9+ugQMHat26deVcOQAAAICqxDLGmIouIk/nzp3VsWNHvfzyy5Ikl8ul+vXra8yYMRo/fny+9nXq1NHDDz+s0aNHu6dde+21CgoK0jvvvFOsdaampioiIkIpKSkKDw/3zhsBAAAAcNaxkw0qzRmp7OxsrVmzRvHx8e5pDodD8fHxWrVqVYF9srKyFBgY6DEtKChIK1asKHQ9WVlZSk1N9XgBAAAAgB2VJkgdPnxYTqdT0dHRHtOjo6OVlJRUYJ+EhARNmzZNf/75p1wul77++mstWLBABw4cKHQ9U6ZMUUREhPtVv359r74PAAAAAOe+ShOkSuLFF1/Ueeedp2bNmsnf31933XWXEhMT5XAU/rYmTJiglJQU92vPnj3lWDEAAACAc0GlCVI1a9aUj4+PkpOTPaYnJycrJiamwD61atXSxx9/rLS0NO3atUu///67QkND1ahRo0LXExAQoPDwcI8XAAAAANhRaYKUv7+/2rdvr6VLl7qnuVwuLV26VF26dCmyb2BgoOrWravc3Fx99NFH6t+/f1mXCwAAAKAK863oAk43duxYjRgxQh06dFCnTp00ffp0paWlKTExUZI0fPhw1a1bV1OmTJEk/fTTT9q3b5/atGmjffv26bHHHpPL5dKDDz5YkW8DAAAAwDmuUgWpIUOG6NChQ5o4caKSkpLUpk0bLVmyxD0Axe7duz3uf8rMzNQjjzyi7du3KzQ0VH379tXbb7+tyMjICnoHAAAAAKqCSvUcqYrAc6QAAAAASGfpc6QAAAAA4GxBkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNvhVdAAAAFSnbmSHLsuSwfGWMSy6TK1+HvxwWvyIBAIXjtwQAoMpxGZecJktpucf085F52pO+VlnOk/KxfBXmF62WkVepafhlMnLJ3xFU0eUCACohghQAoErJdWUpJSdJ3xx4TkmZv+Wbn+48ruSkLfr+4CtqGdFXXWrdJD9HQAVUCgDntlynU9m5TgX6+UqylJWbK18fh/x8fCq6tGIhSFUC6ZnZcliW1v62V8dPpCsyLEjtmteXyxgFB/pXdHkAcM7IcWXpYOYf+njPBOWazDO0zdC6Yx/pUNZWXV3vKfk5AsupSgA4t2Xn5splpK82/KF3f1yvbclHZIxR/RqRur5ra/Vv30KWpEB/v4outUiWMcZUdBEVKTU1VREREUpJSVF4eHi5rtvlcikjK1cz5n2vJSs2Kz0zxz0vONBPl3drrtFDL1FQgJ8cDsYFAYDSMMalY9l7NW/nnco5Q4j6q7jQi9S3zqPy5cwUAJRKZk6Odhw8plv/tUDH0jIKbBMc4KcXh/dTmwZ1FFTOYcpONuDbeQVKz8zRzRPf1YJvfvEIUXnzFizdoJsefU9pGdkVVCEAnDtyTJa+S37RdoiSpB0n/6OkjPyXAQIAis/pcmnf0VQNf2V+oSFKktKzcnTHGx9r876DysrJLccK7al0QWrGjBlq2LChAgMD1blzZ61evbrI9tOnT1fTpk0VFBSk+vXr67777lNmpv1fkuUtPSNbj8/8Qjv3Hy2y3a4DRzXplcVKJ0wBQKlkOU9ob/ovJe6/5uj7yname7EiAKhasnOdenj+l8ooRjjKdbk0/t9flENVJVepgtT8+fM1duxYTZo0SWvXrlXr1q2VkJCggwcPFtj+vffe0/jx4zVp0iT99ttveuONNzR//nw99NBD5Vy5fRlZOVqxblux2q76ZYfSMwlSAFBSOc4MrTn6QamWsSvtZ+WaLC9VBABVz4HjJ/Tr3mRb7dfv2q/KeidSpQpS06ZN06hRo5SYmKgWLVpo1qxZCg4O1uzZswtsv3LlSnXr1k3Dhg1Tw4YN1adPHw0dOvSMZ7EqWk6uUwu//UXFPSaMkRYu/UU5lfjUJgBUZkZG+9LXl3IZLu1L3+idggCgisnMydUHP22w3e/DnzYqLatynlCoNEEqOztba9asUXx8vHuaw+FQfHy8Vq1aVWCfrl27as2aNe7gtH37di1evFh9+/YtdD1ZWVlKTU31eJW3nFynkg6fsNUn6cgJ5ThdZVQRAJzbLMuhLGdaqZeT4Txe+mIAoArKdbp05IT9y6MPn0wv9smH8lZphj8/fPiwnE6noqOjPaZHR0fr999/L7DPsGHDdPjwYXXv3l3GGOXm5ur2228v8tK+KVOm6PHHH/dq7XY5LEsB/vY2fYCfrxyWVUYVAcC5zcglH6v0Iz8xBDoAlIzDkgJ87UePkvQpL5XmjFRJLFu2TE8//bReeeUVrV27VgsWLNCiRYv0xBNPFNpnwoQJSklJcb/27NlTjhWfEuDvq0vaN7bV55L2jW2HLwDAKcYYhfvFlHo5kX51vVANAFQ9AX6+uui8WNv9OjSqK3/fyvmA3krzzbxmzZry8fFRcrLnDWjJycmKiSn4l9+jjz6qG2+8Ubfccosk6cILL1RaWppuvfVWPfzwwwU+eykgIEABARX7HBDLstS2WT1F1whT8pEzX+JXq3qo2rWoL4szUgBQIv6OILWuNkC709eUeBlhvlGqFXieF6sCgKrDx+FQfMsmCg8KUGpG8Qbu8fVxaMhFrRXgV2kii4dKc0bK399f7du319KlS93TXC6Xli5dqi5duhTYJz09PV9Y8vE5lVgr6+geeYykcTfF60zZyLKkcYnxlfbaUAA4G1iWQ7Eh7RXsU63Ey2hVrb/4cxYAlJzLGI24pH2x21/T8QI5HJX3k7dSxbuxY8dqxIgR6tChgzp16qTp06crLS1NiYmJkqThw4erbt26mjJliiSpX79+mjZtmtq2bavOnTtr69atevTRR9WvXz93oKqsAvx81bZZfT11dz89PvMLZWXnH5EvwM9XE++4XO0viOWyPgAoNaN21a/TikOv2e4Z4AjVhZFXycfhXwZ1AahMnE6ncnJyKrqMc5Il6fqOLXQ05YS+3bS1yLbtG9XVPfGd5WNcXn9GrL+/f4FXrtlVqb6dDxkyRIcOHdLEiROVlJSkNm3aaMmSJe4BKHbv3u3xph955BFZlqVHHnlE+/btU61atdSvXz899dRTFfUWbAkK9FPX1nFaMvMOff79Jn354286kZalsJAA9enaXFddeoEsy1JQQOlvkAaAqs7XEaBW1forOXOL/jyxvNj9fCw/Daj/jFcGqwBQeRljlJSUpOPHj1d0Kee8/s3qqE+jKJ3MylLuX0al9nE4FBLgr5AAP+3ft7dM1u9wOBQXFyd//9L9ccwylf0auDKWmpqqiIgIpaSkKDw8vMLqyMl1Kis7Vw7LkssYBfj5ys+vcp9VA4CzUa4rS8uTX9GvKYvO2DbAEaaB9Z9R9YCG8nNU7P21AMrWgQMHdPz4cUVFRSk4OJh708uYyxjJGGXnOpWd65SR5O/rUICvn2SpzEardrlc2r9/v/z8/BQbG5tvP9vJBpXqjFRV5ufrI79KOiIJAJxLfB0BuiT6DrWpPlA/H5mvP08sk9N4XsYT6VdXbaoPVIuIBFnykS+X9AHnNKfT6Q5RNWrUqOhyqpTgClhnrVq1tH//fuXm5srPr+RXGxCkAABVjp8jUDUCGqpn9Bj1jBmj5IwtynCmyNcKUJhflKr515NlObicD6gi8u6JCg6uiK/1KG95l/Q5nU6CFAAAJeHvc+pLU/2QthVcCYDKgMv5qgZv7edKM/w5AAAAAJwtCFIAAABABdq5c6csy9L69esruhTYQJACAAAACjFy5EhZlpXvdfnll5drHTt27NCwYcNUp04dBQYGql69eurfv79+//33cq2juFJTU/Xoo4/qggsuUFBQkGrUqKGOHTvq2Wef1bFjx9ztevTo4d6mgYGBatGihV555ZV88wp69ejRw2OdxhhdccUVsixLH3/8cZm/R+6RAgAAAIpw+eWX68033/SYFhBQfo9EyMnJUe/evdW0aVMtWLBAtWvX1t69e/XFF1+U6XOvcnJySjQYw9GjR9W9e3elpqbqiSeeUPv27RUREaEtW7bozTff1HvvvafRo0e7248aNUqTJ09Wenq65s6dq9GjR6tatWpasGCBsrOzJUl79uxRp06d9M033+iCCy6QpHzPgZo+fXq53ufGGSkAAACgCAEBAYqJifF4VatWTZI0bNgwDRkyxKN9Tk6Oatasqblz50qSlixZou7duysyMlI1atTQVVddpW3bthV7/Zs2bdK2bdv0yiuv6KKLLlKDBg3UrVs3Pfnkk7rooovc7fbu3auhQ4eqevXqCgkJUYcOHfTTTz+558+cOVONGzeWv7+/mjZtqrfffttjPZZlaebMmbr66qsVEhKip556SpL0ySefqF27dgoMDFSjRo30+OOPKzc3t9B6H3roIe3evVurV69WYmKiWrVqpQYNGqhPnz7697//rTvvvNOjfXBwsGJiYtSoUSM99thjOu+88/Tpp5+qevXq7u1dq1YtSVKNGjXc06pXr+5exvr16/X8889r9uzZxd6upUWQAgAAAErohhtu0GeffaaTJ0+6p3355ZdKT0/XwIEDJUlpaWkaO3asfv75Zy1dulQOh0MDBw6Uy+Uq1jpq1aolh8OhDz/8UE6ns8A2J0+e1KWXXqp9+/bp008/1S+//KIHH3zQvY6FCxfqnnvu0d///nf9+uuvuu2225SYmKjvvvvOYzmPPfaYBg4cqI0bN+qmm27SDz/8oOHDh+uee+7R5s2b9eqrr2rOnDnukPVXLpdL8+fP19/+9jfVqVOnwDZnOmsUFBTkPhNVHOnp6Ro2bJhmzJihmJiYYvcrNVPFpaSkGEkmJSWloksBAABABcjIyDCbN282GRkZ+eaNGDHC+Pj4mJCQEI/XU089ZYwxJicnx9SsWdPMnTvX3Wfo0KFmyJAhha7v0KFDRpLZuHGjMcaYHTt2GElm3bp1hfZ5+eWXTXBwsAkLCzM9e/Y0kydPNtu2bXPPf/XVV01YWJg5cuRIgf27du1qRo0a5THtuuuuM3379nX/LMnce++9Hm169eplnn76aY9pb7/9tqldu3aB60lKSjKSzLRp0zymt2vXzr3trr/+evf0Sy+91Nxzzz3GGGNyc3PN22+/bSSZl19+2aN/Udvo1ltvNTfffLPH+1i4cGGB9RlT9P62kw04IwUAAAAUoWfPnlq/fr3H6/bbb5ck+fr6avDgwXr33XclnTr79Mknn+iGG25w9//zzz81dOhQNWrUSOHh4WrYsKEkaffu3cWuYfTo0UpKStK7776rLl266IMPPtAFF1ygr7/+WtKpS9vatm3rcbnb6X777Td169bNY1q3bt3022+/eUzr0KGDx8+//PKLJk+erNDQUPdr1KhROnDggNLT04td/8KFC7V+/XolJCQoIyPDY94rr7yi0NBQBQUFadSoUbrvvvt0xx13FGu5n376qb799ltNnz692LV4C4NNAAAAAEUICQlRkyZNCp1/ww036NJLL9XBgwf19ddfKygoyGNUv379+qlBgwZ6/fXXVadOHblcLrVs2dLW5WuSFBYWpn79+qlfv3568sknlZCQoCeffFK9e/dWUFBQid/f6UJCQjx+PnnypB5//HFdc801+doGBgbmm1arVi1FRkZqy5YtHtNjY2Pd7+GvA2TccMMNevjhhxUUFKTatWvL4Sj+uZ5vv/1W27ZtU2RkpMf0a6+9VhdffLGWLVtW7GXZVaozUvv27dO///1vvfjii9q7d68kyel06ujRo4VevwkAAACcS7p27ar69etr/vz5evfdd3Xddde5R7s7cuSItmzZokceeUS9evVS8+bNPYb/LinLstSsWTOlpaVJklq1aqX169fr6NGjBbZv3ry5fvzxR49pP/74o1q0aFHketq1a6ctW7aoSZMm+V4FBR6Hw6HBgwfrnXfe0f79+4v1XiIiItSkSRPVrVvXVoiSpPHjx2vDhg0eZwsl6YUXXsg30qK3leiMlDFGf//73/Xyyy8rNzdXlmXpwgsvVL169XTy5Ek1bNhQkydP1r333uvlcgEAAIDylZWVpaSkJI9pvr6+qlmzpvvnYcOGadasWfrjjz88BnCoVq2aatSooddee021a9fW7t27NX78eFvrX79+vSZNmqQbb7xRLVq0kL+/v5YvX67Zs2dr3LhxkqShQ4fq6aef1oABAzRlyhTVrl1b69atU506ddSlSxc98MADGjx4sNq2bav4+Hh99tlnWrBggb755psi1z1x4kRdddVVio2N1aBBg+RwOPTLL7/o119/1ZNPPllgn6efflrLli1Tp06dNHnyZHXo0EEhISHasGGDVq1apZYtW9p6/0XJG8Hvr2JjYxUXF+e19RSkRGekpk6dqhdffFH333+/vv76a526p+uUiIgIXXPNNfroo4+8ViQAAABQUZYsWaLatWt7vLp37+7R5oYbbtDmzZtVt25dj3uRHA6H5s2bpzVr1qhly5a67777NHXqVFvrr1evnho2bKjHH39cnTt3Vrt27fTiiy/q8ccf18MPPyzp1DOVvvrqK0VFRalv37668MIL9cwzz8jHx0eSNGDAAL344ot67rnndMEFF+jVV1/Vm2++me+htn+VkJCgzz//XF999ZU6duyoiy66SC+88IIaNGhQaJ8aNWpo9erVGj58uKZOnapOnTrpwgsv1GOPPaYhQ4bo9ddft/X+KyvLnJ6Cium8885T9+7d9eabb+rIkSOqVauWvvnmG1122WWSpGnTpukf//iHkpOTvV6wt6WmpioiIkIpKSkKDw+v6HIAAABQzjIzM7Vjxw7FxcUVeN8Pzi1F7W872aBEZ6T27Nmjrl27Fjo/JCREqampJVk0AAAAAFR6JQpSUVFR2rNnT6Hz16xZ4x6ZAwAAAADONSUKUtdcc41mzZql7du3u6flPaH4q6++0pw5c3Tdddd5p0IAAAAAqGRKFKQef/xx1a5dW23atNHw4cNlWZb+8Y9/qHv37rriiivUqlUrPfTQQ96uFQAAAAAqhRIFqYiICP3nP//Rgw8+qH379ikwMFDLly/X8ePHNWnSJP3www8KDg72dq0AAAAAUCnYfo5UZmamXnvtNbVp00aPPPKIHnnkkbKoCwAAAAAqLdtnpAIDAzVu3Dht2bKlLOoBAAAAgEqvRJf2tWzZUjt37vRyKQAAAABwdihRkHrqqaf06quv6ptvvvF2PQAAAACKwRhT0SVUabbvkZKkl19+WdWrV1dCQoLi4uIUFxenoKAgjzaWZemTTz7xSpEAAAAApIy0LFmW9MPiX5S056hi6lfXxX1byxgpKCSgosurUkoUpDZs2CDLshQbGyun06mtW7fma5P3XCkAAAAApZeVka2FbyzX+zOXKiszxz19xqMfafCdvXTtLT0UEORfZuufMWOGpk6dqqSkJLVu3VovvfSSOnXqVGDbTZs2aeLEiVqzZo127dqlF154Qffee2+Z1VYRShSkuD8KAAAAKD8ZaVla+MZyvf3CknzzsjJz9Pa0JbIsSwMSLymTM1Pz58/X2LFjNWvWLHXu3FnTp09XQkKCtmzZoqioqHzt09PT1ahRI1133XW67777vF5PZVCie6QAAAAAlB/Lkt6fubTINvNnfKOyuihs2rRpGjVqlBITE9WiRQvNmjVLwcHBmj17doHtO3bsqKlTp+r6669XQMC5eclhic5I7d69u1jtYmNjS7J4AAAAAKf5YfEvHpfzFSQrM0c/LN6g3oM6enXd2dnZWrNmjSZMmOCe5nA4FB8fr1WrVnl1XWeTEgWphg0bFuseKKfTWZLFAwAAAPh/LpdR0p6jxWqbvPeojDFeHa/g8OHDcjqdio6O9pgeHR2t33//3WvrOduUKEjNnj07385xOp3auXOn5s6dq6ioKI0ePdorBQIAAABVmcNhKaZ+9WK1ja5XnUHfykmJgtTIkSMLnTdu3Dh17txZKSkpJa0JAAAAwGku7ttaMx79qMjL+wKC/HVx39ZeX3fNmjXl4+Oj5ORkj+nJycmKiYnx+vrOFl4fbCIkJESJiYl64YUXvL1oAAAAoEoyRhp8Z68i2wy5s1eZPKTX399f7du319Kl/xvswuVyaenSperSpYvX13e2KNEZqTNxuVxKSkoqi0UDAAAAVU5QSICuvaWHLMvS/BnfeJyZCgj005DR8brm5kvL7DlSY8eO1YgRI9ShQwd16tRJ06dPV1pamhITEyVJw4cPV926dTVlyhRJpwao2Lx5s/vf+/bt0/r16xUaGqomTZqUSY3lzatBKjU1Vd9//72mTp2qtm3benPRAAAAQJUWEOSvAYmXaOBNl+iHxRuUvPeooutV18V9W8kYlenDeIcMGaJDhw5p4sSJSkpKUps2bbRkyRL3ABS7d++Ww/G/i93279/vkQeee+45Pffcc7r00ku1bNmyMquzPFmmBOf/HA5HoTexGWMUGxurjz/+WG3atCltfWUuNTVVERERSklJUXh4eEWXAwAAgHKWmZmpHTt2KC4uToGBgRVdTrF5e3S+qqKo/W0nG5TojNTEiRPz7TTLslStWjU1btxYffr0ka9vmVw1CAAAAEAiRFWwEqWdxx57zMtlAAAAAMDZo0Sj9l122WUeo3b81XfffafLLrusxEUBAAAAQGVWoiC1bNmyfOPIn+7gwYNavnx5iYsCAAAAgMqsxM+RKuqazK1btyosLKykiwYAAACASq3Y90i99dZbeuutt9w/P/nkk3r99dfztTt+/Lg2bNigvn37eqdCAAAAAKhkih2k0tPTdejQIffPJ06c8BgrXjp1liokJES33367Jk6c6L0qAQAAAKASKXaQuuOOO3THHXdIkuLi4vTiiy/q6quvLrPCAAAAABQsPSNbLmPksCwFl+GDeFG4Eg1/vmPHDm/XAQAAAKAIOblOuYzRr1sP6IsVm5WalqXwkAD17d5CFzSpLYdlyc/Xp6LLrDJK/dTcEydOKCUlRS6XK9+82NjY0i4eAAAAqPIys3K0fd8RPfzyIu0/lOIx77PvN6lOrQg9fdeViqtbQ4EBfhVUZdVS4lH7Zs6cqfPOO0+RkZFq0KCB4uLi8r0AAAAAlE5OrlPb9x3RbU/Ozxei8uw/lKJbn5yvHfuOKCfXWSZ1zJgxQw0bNlRgYKA6d+6s1atXF9r29ddf18UXX6xq1aqpWrVqio+PL7L92ahEQWrWrFkaPXq0mjRpoieffFLGGN17770aP368YmJi1Lp1a73xxhverhUAAACoclzG6KGXP1d2TtEBKTvHqYdeXiSXy3i9hvnz52vs2LGaNGmS1q5dq9atWyshIUEHDx4ssP2yZcs0dOhQfffdd1q1apXq16+vPn36aN++fV6vraKUKEi99NJLSkhI0BdffKFbb71VknTllVfqqaee0ubNm3XixAkdOXLEq4UCAAAAVdGmrQd04FBqsdruP5SizduTvF7DtGnTNGrUKCUmJqpFixaaNWuWgoODNXv27ALbv/vuu7rzzjvVpk0bNWvWTP/617/kcrm0dOlSr9dWUUoUpLZt26Z+/fpJkvz8Tl2DmZ2dLUmKiIjQLbfcoldeecVLJQIAAABVU3pGthav2Gyrz6IfNik9M9trNWRnZ2vNmjWKj493T3M4HIqPj9eqVauKtYz09HTl5OSoevXqXquropUoSEVERCg3N1eSFB4eruDgYO3Zs8c9PywsTElJ3k/CAAAAQFXiMkapaVm2+pxIz/Lq5X2HDx+W0+lUdHS0x/To6Ohif+cfN26c6tSp4xHGznYlClItW7bUL7/84v75oosu0syZM7Vv3z7t2bNHr776qs4//3yvFQkAAABURQ7LUnhIgK0+YcEBcjisMqrIvmeeeUbz5s3TwoULFRgYWNHleE2JgtTf/vY3/frrr8rKOpWOH3/8cf3222+KjY1Vw4YNtWXLFj355JNeLRQAAACoaoKD/NW3ewtbfa68+AIFB3rvIb01a9aUj4+PkpOTPaYnJycrJiamyL7PPfecnnnmGX311Vdq1aqV12qqDEoUpBITE/XTTz8pIOBUOu7WrZs2bdqkadOm6cUXX9SGDRt05ZVXerVQAAAAoCq6oElt1a4VXqy2dWpFqEWjosONXf7+/mrfvr3HQBF5A0d06dKl0H7PPvusnnjiCS1ZskQdOnTwak2Vge0H8mZmZuq1115TmzZtdMkll7inN2rUSPfcc49XiwMAAACqOodlacpdV+nWJ+cXOQS6v5+Pnh5zVZlc1jd27FiNGDFCHTp0UKdOnTR9+nSlpaUpMTFRkjR8+HDVrVtXU6ZMkST94x//0MSJE/Xee++pYcOG7nupQkNDFRoa6vX6KoLtM1KBgYEaN26ctmzZUhb1AAAAADiNn6+P4urW0GuPDFGdWhEFtqlTK0KvPXq94upUl5+vj9drGDJkiJ577jlNnDhRbdq00fr167VkyRL3ABS7d+/WgQMH3O1nzpyp7OxsDRo0SLVr13a/nnvuOa/XVlFsn5GSTg02sXPnTi+XAgAAAKAggQF+ahJbS/OeGaFN2w5o8YrNOpGepbDgAF158QVq0ShGDodVJiEqz1133aW77rqrwHnLli3z+LkqZIUSBamnnnpKw4YNU8+ePc+pIQwBAACAyiovJLVrXl/N4qLlchk5HJZXB5ZA8ZUoSL388suqXr26EhISFBcXp7i4OAUFBXm0sSxLn3zySYmKmjFjhqZOnaqkpCS1bt1aL730kjp16lRg2x49emj58uX5pvft21eLFi0q0foBAACAyozwVPFKFKQ2bNggy7IUGxsrp9OprVu35mtjWSW7yW3+/PkaO3asZs2apc6dO2v69OlKSEjQli1bFBUVla/9ggULlJ39vyc3HzlyRK1bt9Z1111XovUDAAAAwJmUKEiV5TWP06ZN06hRo9wjgMyaNUuLFi3S7NmzNX78+Hztq1ev7vHzvHnzFBwcTJACAAAAUGZK9BypspKdna01a9Z43HflcDgUHx+vVatWFWsZb7zxhq6//nqFhIQUOD8rK0upqakeLwAAAACwo8RByul0at68ebrttts0cOBAbdy4UZKUkpKiBQsW5HvycXEcPnxYTqfTPYxinujoaPfY80VZvXq1fv31V91yyy2FtpkyZYoiIiLcr/r169uuEwAAAEDVVqIgdfz4cXXr1k3Dhg3Tv//9b3366ac6dOiQpFMP2br77rv14osverXQ4njjjTd04YUXFjowhSRNmDBBKSkp7teePXvKsUIAAACgdJwul05mZ+tEVpZOZmfL6XJVdElVUonukRo/frw2bdqkL7/8Um3btvUYBMLHx0eDBg3S4sWL9fTTT9tabs2aNeXj45PvbFZycrJiYmKK7JuWlqZ58+Zp8uTJRbYLCAhQQECArboAAACAipaRkyOHZenb7dv1zfZtOpmdrVB/f8U3aqzLGjWSyxgF+flVdJlVRomC1Mcff6wxY8aod+/eOnLkSL75559/vubMmWN7uf7+/mrfvr2WLl2qAQMGSJJcLpeWLl1a6MO/8nzwwQfKysrS3/72N9vrBQAAACqzjJwczVm3Tm+sXaOjGRke8xb+9puqBwXp5nbtldi2rQIJU+WiREEqJSVFcXFxhc7PyclRbm5uiQoaO3asRowYoQ4dOqhTp06aPn260tLS3KP4DR8+XHXr1tWUKVM8+r3xxhsaMGCAatSoUaL1AgAAAJVRRk6OHvrma33y+++FtjmakaGpP67QH0cOa0p8b8JUOSjRPVKNGzfW2rVrC53/1VdfqUWLFiUqaMiQIXruuec0ceJEtWnTRuvXr9eSJUvcA1Ds3r1bBw4c8OizZcsWrVixQjfffHOJ1gkAAABURnlnoooKUaf75Pff9ea6dcrIyfF6LTNmzFDDhg0VGBiozp07a/Xq1YW2XbBggTp06KDIyEiFhISoTZs2evvtt71eU0Uq0RmpW265RePGjVOPHj3Uq1cvSacewJuVlaXJkydryZIleu2110pc1F133VXopXzLli3LN61p06YyxpR4fQAAAEBl5LAs/WvNz7b6vLF2jW5q186rdcyfP19jx47VrFmz1LlzZ02fPl0JCQnasmWLx3gJeapXr66HH35YzZo1k7+/vz7//HMlJiYqKipKCQkJXq2tolimBAnEGKNbb71Vb7zxhiIjI3X8+HFFR0fryJEjys3N1W233aaZM2eWRb1el5qaqoiICKWkpCg8PLyiywEAAEA5y8zM1I4dOxQXF6fAwMCKLsfN6XLpq61bNXrR57b7vnJVP/Vu3Fg+Du88NrZz587q2LGjXn75ZUmnxjGoX7++xowZo/HjxxdrGe3atdOVV16pJ554wis1lVRR+9tONijRlrUsS6+//rq+//573XjjjbriiivUpk0b3XrrrVq2bNlZE6IAAACAyiojN1ffbN9Wor5fb9uqzBKOWfBX2dnZWrNmjeLj493THA6H4uPjtWrVqjP2N8Zo6dKl2rJliy655BKv1FQZlOjSvjzdu3dX9+7dvVULAAAAgP9njNHJ7OwS9U3LzpHLS7e+HD58WE6n0z1mQZ7o6Gj9XsS9WykpKapbt66ysrLk4+OjV155Rb179/ZKTZVBqYLU0aNH9c0332jnzp2SpLi4OF122WWMnAcAAACUkmVZCvX3L1HfEH8/OSzLyxXZExYWpvXr1+vkyZNaunSpxo4dq0aNGqlHjx4VWpe3lDhIPfbYY/rHP/6hrKwsj+n+/v568MEHz/hgXAAAAACFC/L1VXyjxlr422+2+/Zu3ESBvqU6Z+JWs2ZN+fj4KDk52WN6cnKyYmJiCu3ncDjUpEkTSVKbNm3022+/acqUKedMkCrRPVJPPPGEJk+erPj4eH3xxRfatm2btm3bpsWLFys+Pl5PPfVUhd9EBgAAAJzNfBwOXdaokarZHACjelCQesbFeW2gCX9/f7Vv315Lly51T3O5XFq6dKm6dOlS7OW4XK58J2HOZiWKqbNmzVK/fv30ySefeEyPi4vT5Zdfrn79+mnmzJl69NFHvVIkAAAAUBW5jNEt7Tto6o8rit3n5nbtvXZ/VJ6xY8dqxIgR6tChgzp16qTp06crLS1NiYmJkqThw4erbt26mjJliiRpypQp6tChgxo3bqysrCwtXrxYb7/99jk1KF2JglRKSoouv/zyQuf37du3wOc9AQAAACi+ID8/JbZtqz+OHC7WQ3n7N2umkW3bKsjPz6t1DBkyRIcOHdLEiROVlJSkNm3aaMmSJe4BKHbv3i3HaWfA0tLSdOedd2rv3r0KCgpSs2bN9M4772jIkCFerasileg5UgkJCapdu7bmzJlT4PyRI0cqKSlJS5YsKW19ZY7nSAEAAFRtlfU5UqfLzMnRm+vW6Y21a3Q0IyPf/OpBQbq5XfsyCVHnGm89R6rEl/Zdfvnluu+++zR69Gg1atRIkrR9+3a9/PLL+s9//nNWhCgAAADgbBDo56eRbdvqpnbt9N2OHfp621alZecoxN9PvRs3Uc+4OLmMIUSVoxKdkQoLC5PL5VJmZqYkuU/juVwuSVJAQIB8/zJKiGVZSklJKW29XscZKQAAgKrtbDgjdTqny6XM3Fy5jJHDshTo6+u1gSWqggo9I3XttdfKquBx6QEAAICqyMfhUEgJny8F7ylRkCrs3igAAAAAqAo4BwgAAAAANpXqccfff/+9tm/frmPHjumvt1pZlqX77ruvVMUBAAAAyC/X5ZTTuORjOeTr8KnocqqkEgWp9evXa8iQIdq6dWu+AJWHIAUAAAB4T7YzR7IsbTy+Q2uP/ql0Z5aCfQLUrvp5ujCioSTJ34dR+8pLiYLULbfcooMHD2rWrFnq3LmzIiIivF0XAAAAAEnGGGW5crRgzwp9vHelDmYd95j/7q5vFRUQqQH1uuqa+t0V4PBjYLhyUKIgtWnTJk2ePFmjRo3ydj0AAAAA/p8xRmm5mbpv3Sz9eWJfoe0OZh3Xa9sWa9nBXzSt7e0K8Q0kTJWxEg02cd5557FjAAAAgDKW5co5Y4g63R8n9mnsulnKcuWUcWUoUZB67LHHNGPGDO3bV7wdCgAAAMCebOepy/mKG6Ly/HFinxbu+fHUPVVeNGPGDDVs2FCBgYHq3LmzVq9eXax+8+bNk2VZGjBggFfrqWglurTvmmuuUWZmppo2bapevXqpXr168vHxHC3Esiy9+OKLXikSAAAAqHIsSx/vXVmirh/vW6lrY7t7rZT58+dr7Nix7jESpk+froSEBG3ZskVRUVGF9tu5c6fuv/9+XXzxxV6rpbKwTGHD7hVh+fLluvrqq3XixInCF2xZcjqdpSquPKSmpioiIkIpKSkKDw+v6HIAAABQzjIzM7Vjxw7FxcUpMDCwostxW3P0T/193asl7v9829vUvvp5Xqmlc+fO6tixo15++WVJksvlUv369TVmzBiNHz++wD5Op1OXXHKJbrrpJv3www86fvy4Pv74Y6/UUxpF7W872aBEl/aNGTNG4eHh+vLLL3X8+HG5XK58r7MhRAEAAACVUa7LqbVH/yzVMtYd2yqncZW6luzsbK1Zs0bx8fHuaQ6HQ/Hx8Vq1alWh/SZPnqyoqCjdfPPNpa6hMirRpX1bt27VM888o969e3u7HgAAAKDKcxqX0p1ZpVpGem6Wcl1O+fiU6NyJ2+HDh+V0OhUdHe0xPTo6Wr///nuBfVasWKE33nhD69evL9W6K7MSbdULLrhAKSkp3q4FAAAAgCQfy6Fgn4BSLSPYN0C+Dp8zN/SyEydO6MYbb9Trr7+umjVrlvv6y0uJzkg999xzuuGGG5SQkKBOnTp5uyYAAACgSvN1+Khd9fP07q5vS7yMttWayMcq3dkoSapZs6Z8fHyUnJzsMT05OVkxMTH52m/btk07d+5Uv3793NNcrlOXGPr6+mrLli1q3LhxqeuqaCUKUs8//7zCwsLUpUsXtWjRQrGxsQWO2vfJJ594pUgAAACgqrkwMk5RAZE6mHXcdt/owGq6MLKhV+rw9/dX+/bttXTpUvcQ5i6XS0uXLtVdd92Vr32zZs20ceNGj2mPPPKITpw4oRdffFH169f3Sl0VrURBasOGDbIsS7GxsTp58qQ2b96crw0P7AUAAABKwRgNqNdVr21bbLvrgLpdJdtjcxdu7NixGjFihDp06KBOnTpp+vTpSktLU2JioiRp+PDhqlu3rqZMmaLAwEC1bNnSo39kZKQk5Zt+NitRkNq5c6eXywAAAABwOn8fP11Tv7u+O/iLrYfynh9WVwPrd5O/j5/XahkyZIgOHTqkiRMnKikpSW3atNGSJUvcA1Ds3r1bDkfpLyM8m5ToOVLnEp4jBQAAULVV1udISZIxRmm5mRq7bpb+KEaYOj+srqa1vV0hvoFcIVaICn2OlHTqAVvz5s3TbbfdpoEDB7qvg0xJSdGCBQvy3YwGAAAAwB7LshTiG6h/th+t2xpfqaiAyALbRQVE6rbGV+qf7UcTospJiS7tO378uC6//HKtXr1aoaGhSktL05gxYyRJoaGhuvvuuzV8+HA9/fTTXi0WAAAAqGosy1Kgj7+urd9d18Z218bjO7Xu2Fal52Yp2DdAbas1OTWwhJFXL+dD0UoUpMaPH69Nmzbpyy+/VNu2bRUVFeWe5+Pjo0GDBmnx4sUEKQAAAMBL8kJS++rnqU21xsp1OeXr8PHKEOewr0Rb/eOPP9aYMWPUu3fvAk8bnn/++QxIAQAAAJQRH8uhAB8/QlQFKtGWT0lJUVxcXKHzc3JylJubW+KiAAAAAKAyK9GlfY0bN9batWsLnf/VV1+pRYsWJS4KAAAAgCdjXHKaTOW4UnUye5tyXSfk6whTqH9j+TnC5WMFyuIMVbkpdpD6/vvv1bx5c9WqVUu33HKLxo0bpx49eqhXr16STt0El5WVpcmTJ2vJkiV67bXXyqxoAAAAoKowxiWXcnU4/UdtT52jY5lr8rWpFthejSISVTOoqxzyJVCVg2IHqZ49e+rtt9/WsGHDdM8992jTpk0aOnSo+ynFw4YN05EjR5Sbm6vbbrtNN998c1nVDAAAAFQJLleOsl0p+ikpUWk5OwptdyxzjdZkrlGIXyNdFDNbfo4IORyM4FeWih2kTn9ur2VZev311zVixAh9+OGH+vPPP+VyudS4cWMNHjxYl1xySZkUCwAAAFQVxriU7UrRj/sHKct5uFh90nK2a8X+Qepe50P5W9U5M1WGSnSPVJ7u3bure/fu3qoFAAAAwP9zKVc/Jd1U7BCVJ8t5WP9Juknd634oH/mXUXWwFVF5QjIAAABQ9oxx6XD6j0rL2V6i/mk523U4faWMcXmtphkzZqhhw4YKDAxU586dtXr16kLbzpkzR5ZlebwCAwO9VktlYCtI/e1vf5OPj0+xXr6+pTrZBQAAAFRZTpOp7alzSrWMHalz5DSZXqln/vz5Gjt2rCZNmqS1a9eqdevWSkhI0MGDBwvtEx4ergMHDrhfu3bt8kotlYWttBMfH6/zzz+/rGoBAAAAICnHlVrg6Hx2HM38WTmuVPk6gktdz7Rp0zRq1CglJiZKkmbNmqVFixZp9uzZGj9+fIF9LMtSTExMqdddWdkKUiNGjNCwYcPKqhYAAAAAkk5mb/PScrYryLd0YSY7O1tr1qzRhAkT3NMcDofi4+O1atWqwtd98qQaNGggl8uldu3a6emnn9YFF1xQqloqE4bxAAAAACqZXNeJSrOcw4cPy+l0Kjo62mN6dHS0kpKSCuzTtGlTzZ49W5988oneeecduVwude3aVXv37i11PZUFNzIBAAAAlYyvI6xSLceuLl26qEuXLu6fu3btqubNm+vVV1/VE088USE1eRtnpAAAAIBKJtS/sZeW06jUy6hZs6Z8fHyUnJzsMT05ObnY90D5+fmpbdu22rp1a6nrqSyKHaRcLhf3RwEAAADlwM8RrmqB7Uu1jOqBHeTnCC91Lf7+/mrfvr2WLl3qnuZyubR06VKPs05FcTqd2rhxo2rXrl3qeioLzkgBAAAAlYyPFahG4SNLtYy4iJHysbzz7KaxY8fq9ddf11tvvaXffvtNd9xxh9LS0tyj+A0fPtxjMIrJkyfrq6++0vbt27V27Vr97W9/065du3TLLbd4pZ7KgHukAAAAgErGshyqGdxNIX6NSvRQ3hC/RqoZ1FWW5Z3zJkOGDNGhQ4c0ceJEJSUlqU2bNlqyZIl7AIrdu3fL4fjfuo4dO6ZRo0YpKSlJ1apVU/v27bVy5Uq1aNHCK/VUBpYxxlR0ERUpNTVVERERSklJUXh46U99AgAA4OySmZmpHTt2KC4uToGB3jmD4w3GuJTtPKoV+wcpy3m42P0CfGqqe50P5e9T3WtB6lxS1P62kw3YsgAAAEAlZFkO+Tki1L3OhwrxK96gESF+jdS9zofyc0QQosoYl/YBAAAAlZTD4Sd/q7q61/1Qh9NXakfqHB3N/Dlfu+qBHRQXMVK1grrKki8hqhwQpAAAAIBKzLIc8pG/ooIvUY2gTspxpepk9nbluk7I1xGmUP9G8nOEy8cKJECVI4IUAAAAcBawLId8rWD5OoIV5Fu85zeh7BBZAQAAAElVfAy2KsNb+5kgBQAAgCrNz89PkpSenl7BlaA8ZGdnS5J8fHxKtRwu7QMAAECV5uPjo8jISB08eFCSFBwcLMuyKrgqlAWXy6VDhw4pODhYvr6li0IEKQAAAFR5MTGn7jnKC1M4dzkcDsXGxpY6LFe6IDVjxgxNnTpVSUlJat26tV566SV16tSp0PbHjx/Xww8/rAULFujo0aNq0KCBpk+frr59+5Zj1QAAADibWZal2rVrKyoqSjk5ORVdDsqQv7+/HI7S3+FUqYLU/PnzNXbsWM2aNUudO3fW9OnTlZCQoC1btigqKipf++zsbPXu3VtRUVH68MMPVbduXe3atUuRkZHlXzwAAADOej4+PqW+dwZVg2Uq0fAknTt3VseOHfXyyy9LOnUNY/369TVmzBiNHz8+X/tZs2Zp6tSp+v333903CdqVmpqqiIgIpaSkKDw8vFT1AwAAADh72ckGlWbUvuzsbK1Zs0bx8fHuaQ6HQ/Hx8Vq1alWBfT799FN16dJFo0ePVnR0tFq2bKmnn35aTqez0PVkZWUpNTXV4wUAAAAAdlSaIHX48GE5nU5FR0d7TI+OjlZSUlKBfbZv364PP/xQTqdTixcv1qOPPqrnn39eTz75ZKHrmTJliiIiItyv+vXre/V9AAAAADj3VZogVRIul0tRUVF67bXX1L59ew0ZMkQPP/ywZs2aVWifCRMmKCUlxf3as2dPOVYMAAAA4FxQaQabqFmzpnx8fJScnOwxPTk52T0c5V/Vrl1bfn5+HjcENm/eXElJScrOzpa/v3++PgEBAQoICPBu8QAAAACqlEpzRsrf31/t27fX0qVL3dNcLpeWLl2qLl26FNinW7du2rp1q1wul3vaH3/8odq1axcYogAAAADAGypNkJKksWPH6vXXX9dbb72l3377TXfccYfS0tKUmJgoSRo+fLgmTJjgbn/HHXfo6NGjuueee/THH39o0aJFevrppzV69OiKegsAAAAAqoBKc2mfJA0ZMkSHDh3SxIkTlZSUpDZt2mjJkiXuASh2797t8fCs+vXr68svv9R9992nVq1aqW7durrnnns0bty4inoLAAAAAKqASvUcqYrAc6QAAAAASGfpc6QAAAAA4GxBkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgU6UMUjNmzFDDhg0VGBiozp07a/Xq1YW2nTNnjizL8ngFBgaWY7UAAAAAqppKF6Tmz5+vsWPHatKkSVq7dq1at26thIQEHTx4sNA+4eHhOnDggPu1a9eucqwYAAAAQFVT6YLUtGnTNGrUKCUmJqpFixaaNWuWgoODNXv27EL7WJalmJgY9ys6OrocKwYAAABQ1VSqIJWdna01a9YoPj7ePc3hcCg+Pl6rVq0qtN/JkyfVoEED1a9fX/3799emTZsKbZuVlaXU1FSPFwAAAADYUamC1OHDh+V0OvOdUYqOjlZSUlKBfZo2barZs2frk08+0TvvvCOXy6WuXbtq7969BbafMmWKIiIi3K/69et7/X0AAAAAOLdVqiBVEl26dNHw4cPVpk0bXXrppVqwYIFq1aqlV199tcD2EyZMUEpKivu1Z8+ecq4YAAAAwNnOt6ILOF3NmjXl4+Oj5ORkj+nJycmKiYkp1jL8/PzUtm1bbd26tcD5AQEBCggIKHWtAAAAAKquSnVGyt/fX+3bt9fSpUvd01wul5YuXaouXboUaxlOp1MbN25U7dq1y6pMAAAAAFVcpTojJUljx47ViBEj1KFDB3Xq1EnTp09XWlqaEhMTJUnDhw9X3bp1NWXKFEnS5MmTddFFF6lJkyY6fvy4pk6dql27dumWW26pyLcBAAAA4BxW6YLUkCFDdOjQIU2cOFFJSUlq06aNlixZ4h6AYvfu3XI4/nci7dixYxo1apSSkpJUrVo1tW/fXitXrlSLFi0q6i0AAAAAOMdZxhhT0UVUpNTUVEVERCglJUXh4eEVXQ4AAACACmInG1Sqe6QAAAAA4GxAkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgBQAAAAA2EaQAAAAAwCaCFAAAAADYRJACAAAAAJsIUgAAAABgE0EKAAAAAGwiSAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbPKt6AIAAKhoxjglkyNZliwroKLLAQCcBQhSAIAqybjSJctHyvlVyv6vjOugJF/Jr7nk30lyVJMUIMvyqehSAQCVEEGqgjmNU7kup/ZnHNTm1G06mZuuUN9gNQ9vrLpBUfKxfOTr4Jc4AHiLMbmScmTSZkrp8yST4jk/7x9+rWSFjZPxvUCWI7i8ywSAKsNlTn3yOiyrgiuxhyBVgbKd2fr+8Bp9uu877Urfn29+g+A6urpOD11cq4MCfPwroEIAOLcYkyU598gcu01y7im6cc4GmaM3SEFDpPCHZVmB5VMkAFQB6Tk58rEsfbdzh7YcOSRjpLhq1dSnURO5jFGIf+X/7msZY8yZm527UlNTFRERoZSUFIWHh5fbetNzM/X4phn6/cSOM7ZtGhanxy64U0E+gbLOsqQOAJWFMU7JuUvmyCDJnLTXOaC3rMjnCVMAUEoul0sZubma/tNKfbh5k1KyMj3mB/v5aUDT5rq/a3eF+vnL16d8r8yykw0Yta8CZDqz9eiv/yxWiJKkLSd26NFfX1KWK6eMKwOAc1n2qTNRdkOUJGV9LaV/IGMyvF8WAFQRxhilZGWp//x39ca6NflClHTqTNV7v25Q3/fmKjktTbkuVwVUWjwEqXKW5czWh3u+1NaTu23123pyt+bv/kJZzuwyqgwAzl3GlSlz8g3Juavkyzjx7KmR/QAAJZLtdOqGBe9r+7GjZ2ybdPKkrv9ovrKdueVQWclUyiA1Y8YMNWzYUIGBgercubNWr15drH7z5s2TZVkaMGBA2RZYCpZl6cukH0vU9+vklVzaBwAlYVlSxrulXEiWlP7vU/dZAQBscbpc+nbndv1+5HCx++w7kap5v25Udm7lDFOVLkjNnz9fY8eO1aRJk7R27Vq1bt1aCQkJOnjwYJH9du7cqfvvv18XX3xxOVVqn8u49PPRX5WaW4LLSiSdyE3T6iMb5azEpzgBoFLK3S65jpR6MSbzS85KAUAJZDlz9a+1P9vuN3fDOlXWAR0qXZCaNm2aRo0apcTERLVo0UKzZs1ScHCwZs+eXWgfp9OpG264QY8//rgaNWpUjtXak+nM1n+ObCjVMn46ukFZLi7vA4DiMsZI2Wu9s7DcLRIDTgCAbTlOl9YlHbDdb3dKivafSC2DikqvUgWp7OxsrVmzRvHx8e5pDodD8fHxWrVqVaH9Jk+erKioKN18881nXEdWVpZSU1M9XuXFyOhkbnqplpGWmy5TaXM5AFRGThlXspeWlSMZ/pgFAHalFjCwRHEdyyx537JUqYLU4cOH5XQ6FR0d7TE9OjpaSUlJBfZZsWKF3njjDb3++uvFWseUKVMUERHhftWvX7/Uddvh7/ArVX+/UvYHgKrHIcvy4vNILB6SDgB2+fmU/PG1Ab6V89G3lSpI2XXixAndeOONev3111WzZs1i9ZkwYYJSUlLcrz17zvBARi/ys3xVNyj6zA2LUCcwSr78EgeAYrMsh+TXyjsLc8R4ZzkAUMVUCwxUZKD9S6P9fXzUICLS+wV5QaWKdzVr1pSPj4+Skz0vwUhOTlZMTP5fXtu2bdPOnTvVr18/9zTX/w/E4Ovrqy1btqhx48YefQICAhQQEFAG1Z+Zv4+frqxziT7a+1WJLs+zZKlfnR4K8Kn8T3oGgErFr7VO/e2wlIP1+Lc/NdiEVTG/RwDgbOU0Rte1aKnXbQ44cXnj88qootKrVGek/P391b59ey1dutQ9zeVyaenSperSpUu+9s2aNdPGjRu1fv169+vqq69Wz549tX79+nK/bK84ghwBahPZrER9W0c2VZAvv7wBwD5fKeCSUi/FCk6U5Qj1Qj0AULUE+/np5rbt5euwFz9u79BJof6V8yRCpTojJUljx47ViBEj1KFDB3Xq1EnTp09XWlqaEhMTJUnDhw9X3bp1NWXKFAUGBqply5Ye/SMjIyUp3/TKItAnQCPjBmjj+j+Va4o/Jr6v5asRDQco0EGQAgC7LEeIFDZOJusHSc6SLcT/IsnvfK/WBQBVSah/gKbGX677vlpcrPbjul2s2Ep6WZ9Uyc5ISdKQIUP03HPPaeLEiWrTpo3Wr1+vJUuWuAeg2L17tw4csD90YmVhWZZqB9bSg81uko9VvM3vYzn0QNNE1Q2K4oG8AFBSjtpSyOiS9bXCZUVMk8XQ5wBQYsF+furduIlevuKqIs8yBfj46vEel2l4q7YK9qu8A61ZxpgqPZZ2amqqIiIilJKSovDw8HJbb6YzWzvS9uqlP9/RvozCHzZcNyhKdzUZpkahsQrk3igAKBVjMmVS/yFlvFv8TlaErOrvSr4NZHFvFACUWkZOjmRJn235Xe9sWK9dKSmSjGqHhmloy1Ya1KKlLEsK9iv/7752sgFBqoKClCTlunLlktGOtL1auHep/jy5Sxm5mQryDVST0FhdUzdecSH15LAs+Toq3VWYAHBWMiZDyvpeJuVRyRwvurF/d1mRz0lWCCEKALws1+VSVm6u/H18ZFmWsp1O+Toc8vepuBGqCVI2VGSQOl16bqZ8LId8LIecxiWncSnYl0tIAKAsGJMlyUgZi2UyP5NyNv1/qHJIPnGSf1tZwSMl3/qyrKCKLRYAUG7sZANOc1QSp4cmdgoAlK28s0sm6GpZgb0lK1Cnbhu2JJMpyZwaoAIAgELwnR0AUGVZlq9khf1lYnDFFAMAOKtUulH7AAAAAKCyI0gBAAAAgE0EKQAAAACwiSAFAAAAADYRpAAAAADAJoIUAAAAANhEkAIAAAAAmwhSAAAAAGATQQoAAAAAbPKt6AIqmjFGkpSamlrBlQAAAACoSHmZIC8jFKXKB6kTJ05IkurXr1/BlQAAAACoDE6cOKGIiIgi21imOHHrHOZyubR//36FhYXJsqyKLkepqamqX7++9uzZo/Dw8Iou55zD9i1bbN+yxfYtW2zfssX2LVts37LF9i1blWn7GmN04sQJ1alTRw5H0XdBVfkzUg6HQ/Xq1avoMvIJDw+v8APpXMb2LVts37LF9i1bbN+yxfYtW2zfssX2LVuVZfue6UxUHgabAAAAAACbCFIAAAAAYBNBqpIJCAjQpEmTFBAQUNGlnJPYvmWL7Vu22L5li+1btti+ZYvtW7bYvmXrbN2+VX6wCQAAAACwizNSAAAAAGATQQoAAAAAbCJIAQAAAIBNBCkAAAAAsIkgVQ6+//579evXT3Xq1JFlWfr444895htjNHHiRNWuXVtBQUGKj4/Xn3/+6dHm6NGjuuGGGxQeHq7IyEjdfPPNOnnyZDm+i8qrqO2bk5OjcePG6cILL1RISIjq1Kmj4cOHa//+/R7LaNiwoSzL8ng988wz5fxOKqczHb8jR47Mt+0uv/xyjzYcv4U70/b967bNe02dOtXdhuO3cFOmTFHHjh0VFhamqKgoDRgwQFu2bPFok5mZqdGjR6tGjRoKDQ3Vtddeq+TkZI82u3fv1pVXXqng4GBFRUXpgQceUG5ubnm+lUrpTNv36NGjGjNmjJo2baqgoCDFxsbq7rvvVkpKisdyCjrG582bV95vp9IpzvHbo0ePfNvu9ttv92jD8VuwM23fnTt3FvoZ/MEHH7jbcfwWbObMmWrVqpX7IbtdunTRF1984Z5/Lnz2EqTKQVpamlq3bq0ZM2YUOP/ZZ5/VP//5T82aNUs//fSTQkJClJCQoMzMTHebG264QZs2bdLXX3+tzz//XN9//71uvfXW8noLlVpR2zc9PV1r167Vo48+qrVr12rBggXasmWLrr766nxtJ0+erAMHDrhfY8aMKY/yK70zHb+SdPnll3tsu3//+98e8zl+C3em7Xv6dj1w4IBmz54ty7J07bXXerTj+C3Y8uXLNXr0aP3nP//R119/rZycHPXp00dpaWnuNvfdd58+++wzffDBB1q+fLn279+va665xj3f6XTqyiuvVHZ2tlauXKm33npLc+bM0cSJEyviLVUqZ9q++/fv1/79+/Xcc8/p119/1Zw5c7RkyRLdfPPN+Zb15ptvehzDAwYMKOd3U/kU5/iVpFGjRnlsu2effdY9j+O3cGfavvXr18/3Gfz4448rNDRUV1xxhceyOH7zq1evnp555hmtWbNGP//8sy677DL1799fmzZtknSOfPYalCtJZuHChe6fXS6XiYmJMVOnTnVPO378uAkICDD//ve/jTHGbN682Ugy//3vf91tvvjiC2NZltm3b1+51X42+Ov2Lcjq1auNJLNr1y73tAYNGpgXXnihbIs7BxS0fUeMGGH69+9faB+O3+IrzvHbv39/c9lll3lM4/gtvoMHDxpJZvny5caYU5+3fn5+5oMPPnC3+e2334wks2rVKmOMMYsXLzYOh8MkJSW528ycOdOEh4ebrKys8n0Dldxft29B3n//fePv729ycnLc04pz7KPg7XvppZeae+65p9A+HL/FV5zjt02bNuamm27ymMbxW3zVqlUz//rXv86Zz17OSFWwHTt2KCkpSfHx8e5pERER6ty5s1atWiVJWrVqlSIjI9WhQwd3m/j4eDkcDv3000/lXvPZLiUlRZZlKTIy0mP6M888oxo1aqht27aaOnVqpTp1XNktW7ZMUVFRatq0qe644w4dOXLEPY/j13uSk5O1aNGiAv+az/FbPHmXlFWvXl2StGbNGuXk5Hh8Bjdr1kyxsbEen8EXXnihoqOj3W0SEhKUmprq/ssqTvnr9i2sTXh4uHx9fT2mjx49WjVr1lSnTp00e/ZsGR5zmU9h2/fdd99VzZo11bJlS02YMEHp6enueRy/xXem43fNmjVav359gZ/BHL9FczqdmjdvntLS0tSlS5dz5rPX98xNUJaSkpIkyeMgyfs5b15SUpKioqI85vv6+qp69eruNiiezMxMjRs3TkOHDlV4eLh7+t1336127dqpevXqWrlypSZMmKADBw5o2rRpFVjt2eHyyy/XNddco7i4OG3btk0PPfSQrrjiCq1atUo+Pj4cv1701ltvKSwszOPSB4njt7hcLpfuvfdedevWTS1btpR06vPV398/3x9W/voZXNBndN48nFLQ9v2rw4cP64knnsh3ae/kyZN12WWXKTg4WF999ZXuvPNOnTx5UnfffXd5lH5WKGz7Dhs2TA0aNFCdOnW0YcMGjRs3Tlu2bNGCBQskcfwWV3GO3zfeeEPNmzdX165dPaZz/BZu48aN6tKlizIzMxUaGqqFCxeqRYsWWr9+/Tnx2UuQQpWRk5OjwYMHyxijmTNneswbO3as+9+tWrWSv7+/brvtNk2ZMkUBAQHlXepZ5frrr3f/+8ILL1SrVq3UuHFjLVu2TL169arAys49s2fP1g033KDAwECP6Ry/xTN69Gj9+uuvWrFiRUWXck460/ZNTU3VlVdeqRYtWuixxx7zmPfoo4+6/922bVulpaVp6tSpfBE9TWHb9/RQeuGFF6p27drq1auXtm3bpsaNG5d3mWetMx2/GRkZeu+99zyO1Twcv4Vr2rSp1q9fr5SUFH344YcaMWKEli9fXtFleQ2X9lWwmJgYSco3SklycrJ7XkxMjA4ePOgxPzc3V0ePHnW3QdHyQtSuXbv09ddfe5yNKkjnzp2Vm5urnTt3lk+B55BGjRqpZs2a2rp1qySOX2/54YcftGXLFt1yyy1nbMvxm99dd92lzz//XN99953q1avnnh4TE6Ps7GwdP37co/1fP4ML+ozOm4fCt2+eEydO6PLLL1dYWJgWLlwoPz+/IpfXuXNn7d27V1lZWWVV8lnlTNv3dJ07d5Ykj89gjt+iFWf7fvjhh0pPT9fw4cPPuDyO3//x9/dXkyZN1L59e02ZMkWtW7fWiy++eM589hKkKlhcXJxiYmK0dOlS97TU1FT99NNP6tKliySpS5cuOn78uNasWeNu8+2338rlcrk/MFG4vBD1559/6ptvvlGNGjXO2Gf9+vVyOBz5LknDme3du1dHjhxR7dq1JXH8essbb7yh9u3bq3Xr1mdsy/H7P8YY3XXXXVq4cKG+/fZbxcXFecxv3769/Pz8PD6Dt2zZot27d3t8Bm/cuNHjDwJ5f5Bp0aJF+byRSupM21c69TutT58+8vf316effprvjGpB1q9fr2rVqlX5M6rF2b5/tX79ekny+Azm+C2Yne37xhtv6Oqrr1atWrXOuFyO38K5XC5lZWWdO5+9FTjQRZVx4sQJs27dOrNu3TojyUybNs2sW7fOPWrcM888YyIjI80nn3xiNmzYYPr372/i4uJMRkaGexmXX365adu2rfnpp5/MihUrzHnnnWeGDh1aUW+pUilq+2ZnZ5urr77a1KtXz6xfv94cOHDA/cob8WXlypXmhRdeMOvXrzfbtm0z77zzjqlVq5YZPnx4Bb+zyqGo7XvixAlz//33m1WrVpkdO3aYb775xrRr186cd955JjMz070Mjt/CnenzwRhjUlJSTHBwsJk5c2a+/hy/RbvjjjtMRESEWbZsmcf///T0dHeb22+/3cTGxppvv/3W/Pzzz6ZLly6mS5cu7vm5ubmmZcuWpk+fPmb9+vVmyZIlplatWmbChAkV8ZYqlTNt35SUFNO5c2dz4YUXmq1bt3q0yc3NNcYY8+mnn5rXX3/dbNy40fz555/mlVdeMcHBwWbixIkV+dYqhTNt361bt5rJkyebn3/+2ezYscN88sknplGjRuaSSy5xL4Pjt3DF+Xwwxpg///zTWJZlvvjii3zL4Pgt3Pjx483y5cvNjh07zIYNG8z48eONZVnmq6++MsacG5+9BKly8N133xlJ+V4jRowwxpwaAv3RRx810dHRJiAgwPTq1cts2bLFYxlHjhwxQ4cONaGhoSY8PNwkJiaaEydOVMC7qXyK2r47duwocJ4k89133xljjFmzZo3p3LmziYiIMIGBgaZ58+bm6aef9ggCVVlR2zc9Pd306dPH1KpVy/j5+ZkGDRqYUaNGeQxVagzHb1HO9PlgjDGvvvqqCQoKMsePH8/Xn+O3aIX9/3/zzTfdbTIyMsydd95pqlWrZoKDg83AgQPNgQMHPJazc+dOc8UVV5igoCBTs2ZN8/e//91j+O6q6kzbt7DjW5LZsWOHMebU4xDatGljQkNDTUhIiGndurWZNWuWcTqdFffGKokzbd/du3ebSy65xFSvXt0EBASYJk2amAceeMCkpKR4LIfjt2DF+XwwxpgJEyaY+vXrF3hMcvwW7qabbjINGjQw/v7+platWqZXr17uEGXMufHZaxnD+IwAAAAAYAf3SAEAAACATQQpAAAAALCJIAUAAAAANhGkAAAAAMAmghQAAAAA2ESQAgAAAACbCFIAAAAAYBNBCgAAAABsIkgBACoFy7J01113Vci6H3vsMVmWpcOHD5fpeho2bKiRI0eW6ToAAOWDIAUAKFPbtm3TbbfdpkaNGikwMFDh4eHq1q2bXnzxRWVkZFR0eV6xceNGDRo0SA0aNFBgYKDq1q2r3r1766WXXqro0gAAZcS3ogsAAJy7Fi1apOuuu04BAQEaPny4WrZsqezsbK1YsUIPPPCANm3apNdee62iyyyVlStXqmfPnoqNjdWoUaMUExOjPXv26D//+Y9efPFFjRkzxt12y5Ytcjj4GyYAnAsIUgCAMrFjxw5df/31atCggb799lvVrl3bPW/06NHaunWrFi1aVIEVesdTTz2liIgI/fe//1VkZKTHvIMHD3r8HBAQUI6VAQDKEn8WAwCUiWeffVYnT57UG2+84RGi8jRp0kT33HNPvukff/yxWrZsqYCAAF1wwQVasmSJx/yRI0eqYcOG+frl3ed0urz7rs60zILs2rVLTZo0UcuWLZWcnFxou23btumCCy7IF6IkKSoqyuPnv94jZVlWoa+dO3e62/3+++8aNGiQqlevrsDAQHXo0EGffvrpGd8DAKDscEYKAFAmPvvsMzVq1Ehdu3Ytdp8VK1ZowYIFuvPOOxUWFqZ//vOfuvbaa7V7927VqFGjRHWUZJnbtm3TZZddpurVq+vrr79WzZo1C11+gwYNtGrVKv36669q2bKlrdrefvvtfNMeeeQRHTx4UKGhoZKkTZs2qVu3bqpbt67Gjx+vkJAQvf/++xowYIA++ugjDRw40NY6AQDeQZACAHhdamqq9u3bp/79+9vq99tvv2nz5s1q3LixJKlnz55q3bq1/v3vf5d4RD+7y/z999/Vq1cv1a1bV19++aWqVatW5PLvv/9+XXHFFWrTpo06deqkiy++WL169VLPnj3l5+dXZN+//e1vHj9PnTpVu3bt0ty5c93h7Z577lFsbKz++9//ui8NvPPOO9W9e3eNGzeOIAUAFYRL+wAAXpeamipJCgsLs9UvPj7eHXgkqVWrVgoPD9f27dtLXIudZf7666+69NJL1bBhQ33zzTdnDFGS1Lt3b61atUpXX321fvnlFz377LNKSEhQ3bp1bV1+991332nChAkaM2aMbrzxRknS0aNH9e2332rw4ME6ceKEDh8+rMOHD+vIkSNKSEjQn3/+qX379hV7HQAA7yFIAQC8Ljw8XJJ04sQJW/1iY2PzTatWrZqOHTtW4lrsLLNfv34KCwvTl19+6X4PxdGxY0ctWLBAx44d0+rVqzVhwgSdOHFCgwYN0ubNm8/Yf+/evRoyZIi6deumadOmuadv3bpVxhg9+uijqlWrlsdr0qRJkvIPaAEAKB9c2gcA8Lrw8HDVqVNHv/76q61+Pj4+BU43xrj//dcBJfI4nc4SLzPPtddeq7feekvvvvuubrvttjOVm4+/v786duyojh076vzzz1diYqI++OADd+gpSHZ2tgYNGqSAgAC9//778vX9369ml8sl6dTlgwkJCQX2b9Kkie06AQClR5ACAJSJq666Sq+99ppWrVqlLl26eG251apV0/Hjx/NN37VrV6mXPXXqVPn6+roHphg2bFiJl9WhQwdJ0oEDB4psd/fdd2v9+vX6/vvvFR0d7TGvUaNGkiQ/Pz/Fx8eXuBYAgPdxaR8AoEw8+OCDCgkJ0S233FLg8OHbtm3Tiy++aHu5jRs3VkpKijZs2OCeduDAAS1cuLBU9Uqnzna99tprGjRokEaMGFGse5y+++67As9uLV68WJLUtGnTQvu++eabevXVVzVjxgx16tQp3/yoqCj16NFDr776aoGB7NChQ2esDwBQNjgjBQAoE40bN9Z7772nIUOGqHnz5ho+fLhatmyp7OxsrVy5Uh988IHHM5WK6/rrr3ePVnf33XcrPT1dM2fO1Pnnn6+1a9eWum6Hw6F33nlHAwYM0ODBg7V48WJddtllhbYfM2aM0tPTNXDgQDVr1sz9/ubPn6+GDRsqMTGxwH6HDx/WnXfeqRYtWiggIEDvvPOOx/yBAwcqJCREM2bMUPfu3XXhhRdq1KhRatSokZKTk7Vq1Srt3btXv/zyS6nfMwDAPoIUAKDMXH311dqwYYOmTp2qTz75RDNnzlRAQIBatWql559/XqNGjbK9zBo1amjhwoUaO3asHnzwQcXFxWnKlCn6888/vRKkpFOX0n344Ye64oor1L9/f33zzTfq3LlzgW2fe+45ffDBB1q8eLFee+01ZWdnKzY2VnfeeaceeeSRAh/UK0knT55UZmamNm/e7B6l73Q7duxQSEiIWrRoof9r3w5qAAaBIIpuTeADgyQ4QRBW0NAaaA+T9Piegz3+ZHbvXXPOWmvVOadaa9V7rzHGL/cCkLvutz0CAAAAn/xIAQAAhIQUAABASEgBAACEhBQAAEBISAEAAISEFAAAQEhIAQAAhIQUAABASEgBAACEhBQAAEBISAEAAISEFAAAQOgBXW1c5v6wKsAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Création du graphique avec seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=formated_results, x='chunk_size', y='temperature',\n",
    "                hue='eval_score_GPT4', size='eval_score_GPT4', \n",
    "                palette='viridis', sizes=(50, 200))\n",
    "\n",
    "# Titre et labels\n",
    "plt.title('Eval score par temperature vs chunk_size', fontsize=16)\n",
    "plt.xlabel('Chunk Size', fontsize=12)\n",
    "plt.ylabel('Temperature', fontsize=12)\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.legend(title='Eval Score GPT4')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-IHN9N-5k-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
